{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dcce2fc",
   "metadata": {},
   "source": [
    "source: [link](https://ai-bootcamp.ruangguru.com/learn/08_langchain/05_agent.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5527b62",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898543f3",
   "metadata": {},
   "source": [
    "# What is an Agent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de9be72",
   "metadata": {},
   "source": [
    "Large Language Models (LLMs) are not just knowledge stores filled with information but also act as reasoning engines. They utilize their background knowledge, together with fresh information provided, to help users make decisions, reason through content, or identify next steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e776687e",
   "metadata": {},
   "source": [
    "LangChain’s Agents are a powerful component that allows the connection of an LLM with different tools, databases, APIs, and functions. LangChain’s Agent is a new and evolving area that brings exciting possibilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3051c09",
   "metadata": {},
   "source": [
    "LangChain agents are, therefore, a great way to employ a language model as a reasoning engine that can interactively connect to various data sources and functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e09723",
   "metadata": {},
   "source": [
    "# Behind the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b27bc2d",
   "metadata": {},
   "source": [
    "LangChain agents work by continuously looping through steps of action, observation, and thought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4eeb31a",
   "metadata": {},
   "source": [
    "The logic behind the agent comes from the ReAct (Reason+Act) prompting, which enables the language model to take actions and reason about those actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d56b5a",
   "metadata": {},
   "source": [
    "# ReAct (Reason+Act) Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd225cdf",
   "metadata": {},
   "source": [
    "ReAct (Reason + Act) is a framework for reasoning and acting in language models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02acb52",
   "metadata": {},
   "source": [
    "ReAct allows for a synergistic relationship between reasoning and action, enhancing the model’s ability to induce, track, and update action plans, handle exceptions, and interface with external sources for additional information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ae5cd4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "237445b6",
   "metadata": {},
   "source": [
    "![Image](https://react-lm.github.io/files/diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd70536",
   "metadata": {},
   "source": [
    "ReAct improves human interpretability and trustworthiness of the models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19930a6",
   "metadata": {},
   "source": [
    "In question answering and fact verification tasks, ReAct overcomes hallucination and error propagation issues by interacting with a external source like a Wikipedia API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700ebe1",
   "metadata": {},
   "source": [
    "In interactive decision-making benchmarks, ReAct outperforms imitation and reinforcement learning methods, showing significant improvements in success rates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ffc699",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c67c6404",
   "metadata": {},
   "source": [
    "![Image](https://tsmatz.files.wordpress.com/2023/03/20230307_paper_example.jpg?w=829)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b26ed6a",
   "metadata": {},
   "source": [
    "The Different result of using Reason Only & Act Only VS ReAct Prompting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254eaf01",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6adac47",
   "metadata": {},
   "source": [
    "![Image](https://react-lm.github.io/files/hotpotqa.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f91ade",
   "metadata": {},
   "source": [
    "# Main Concept Utilizing LangChain Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f3229",
   "metadata": {},
   "source": [
    "Load the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1324aac9",
   "metadata": {},
   "source": [
    "Start by loading the desired agent from the list of supported agents. Ensure the correct string is used to reference the supported agent class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5b4f0d",
   "metadata": {},
   "source": [
    "Choose a Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d827c",
   "metadata": {},
   "source": [
    "Next, select the tool based on specific needs. Each tool serves a unique function and is designed to accept a string as input and return a string as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f486b2",
   "metadata": {},
   "source": [
    "Interact with the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3748a5",
   "metadata": {},
   "source": [
    "Once the agent and tool are set up, interaction with the agent can begin by providing it with relevant input. The agent, powered by the Large Language Model (LLM), will determine the actions to take and the sequence in which they should occur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84cd67f",
   "metadata": {},
   "source": [
    "Observe the Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13032d06",
   "metadata": {},
   "source": [
    "Finally, the agent will either utilize the tool and provide the output or return an output to the user, depending on the task at hand. This output can provide valuable insights or actions based on the input provided to the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd01d6",
   "metadata": {},
   "source": [
    "# Main Types of Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb8d1f2",
   "metadata": {},
   "source": [
    "Langchain uses two main types of agents: Action Agents and Plan-and-Execute Agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852f5f6",
   "metadata": {},
   "source": [
    "# Action Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374a142",
   "metadata": {},
   "source": [
    "Action Agents take one action at a time based on user input. They decide which tool to use and what input to give to that tool. The tool is then called with the input, and an observation is recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df237189",
   "metadata": {},
   "source": [
    "This process is repeated until the agent decides it no longer needs to use a tool, and then it responds directly to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359d159a",
   "metadata": {},
   "source": [
    "At a high-level an action agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346446b",
   "metadata": {},
   "source": [
    "Receives user input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcb9324",
   "metadata": {},
   "source": [
    "Decides which tool, if any, to use and the tool input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d36277",
   "metadata": {},
   "source": [
    "Calls the tool and records the output (also known as an “observation”)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b126e56b",
   "metadata": {},
   "source": [
    "Decides the next step using the history of tools, tool inputs, and observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e0d8a9",
   "metadata": {},
   "source": [
    "Repeats 3-4 until it determines it can respond directly to the user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee5d302",
   "metadata": {},
   "source": [
    "Action agents are wrapped in agent executors, chains which are responsible for calling the agent, getting back an action and action input, calling the tool that the action references with the generated input, getting the output of the tool, and then passing all that information back into the agent to get the next action it should take."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "440d6e38",
   "metadata": {},
   "source": [
    "Key components of Action Agents include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38622da5",
   "metadata": {},
   "source": [
    "Agent: Contains the application logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f382b7",
   "metadata": {},
   "source": [
    "Tools: Actions an agent can take."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2521117d",
   "metadata": {},
   "source": [
    "Toolkits: Groups of tools designed for a specific use case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69fe7c7",
   "metadata": {},
   "source": [
    "Agent Executor: Wraps an agent and a list of tools, responsible for running the agent iteratively until the stopping criteria is met."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bff8421",
   "metadata": {},
   "source": [
    "# Plan and Execute Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f415ba6",
   "metadata": {},
   "source": [
    "Plan-and-Execute Agents first decide a plan of actions to take, and then execute those actions one at a time. The planner lists out the steps to take, and the executor goes through the list of steps, executing them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e7a913",
   "metadata": {},
   "source": [
    "The most typical implementation is to have the planner be a language model, and the executor be an action agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316c99a",
   "metadata": {},
   "source": [
    "The power of these agents comes from the large language model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee56077",
   "metadata": {},
   "source": [
    "With clever prompt design, the workflow is put through the language model, which then instructs what to do next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3b5ede",
   "metadata": {},
   "source": [
    "At a high-level a plan-and-execute agent:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b82a56",
   "metadata": {},
   "source": [
    "Receives user input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f11874c",
   "metadata": {},
   "source": [
    "Plans the full sequence of steps to take"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbedc31c",
   "metadata": {},
   "source": [
    "Executes the steps in order, passing the outputs of past steps as inputs to future steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f476694",
   "metadata": {},
   "source": [
    "The most typical implementation is to have the planner be a language model, and the executor be an action agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed9b2ff",
   "metadata": {},
   "source": [
    "An example of this is the LLM chat agent, which consists of:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1d5701",
   "metadata": {},
   "source": [
    "PromptTemplate: Instructs the language model on what to do."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507ae01",
   "metadata": {},
   "source": [
    "ChatModel: The language model that powers the agent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc382fc0",
   "metadata": {},
   "source": [
    "Stop sequence: Instructs the language model to stop generating as soon as this string is found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce69df7",
   "metadata": {},
   "source": [
    "OutputParser: Parses the language model output into an AgentAction or AgentFinish object."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcb5246",
   "metadata": {},
   "source": [
    "# LangChain Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d1c9b0",
   "metadata": {},
   "source": [
    "A LangChain Tool is a function designed to perform a specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eaedee",
   "metadata": {},
   "source": [
    "Examples of tools can range from Google Search, database lookups, Python REPL, to other chains. The standard interface for a tool is a function that accepts a string as input and returns a string as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcbf05",
   "metadata": {},
   "source": [
    "The standard interface for a tool is a function that accepts a string as input and returns a string as output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4863ae8",
   "metadata": {},
   "source": [
    "# Built-in Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc0aaf2",
   "metadata": {},
   "source": [
    "LangChain comes with a set of built-in tools that can be used to perform various tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46ee9e0",
   "metadata": {},
   "source": [
    "Agents are programmed to use necessary tools depending on the type of question asked."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff169d93",
   "metadata": {},
   "source": [
    "We can find the list of all available tools in this link:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6827a021",
   "metadata": {},
   "source": [
    "https://python.langchain.com/docs/integrations/tools/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3aab06",
   "metadata": {},
   "source": [
    "# Example use of Builtin tools: LLM-Math & Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132f0d4b",
   "metadata": {},
   "source": [
    "Agents can also utilize databases like Wikipedia to answer questions requiring historical or specific knowledge not requiring recent data, such as details about a specific person."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60734b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langchain\n",
    "\n",
    "langchain.debug=True\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37a4c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "OpenAIModel = \"gpt-4\"\n",
    "llm = ChatOpenAI(model=OpenAIModel, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2546c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U wikipedia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f851c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Requirement already up-to-date: wikipedia in /home/eddypermana22/.local/lib/python3.8/site-packages (1.4.0)\n",
    "Requirement already satisfied, skipping upgrade: requests<3.0.0,>=2.0.0 in /home/eddypermana22/.local/lib/python3.8/site-packages (from wikipedia) (2.31.0)\n",
    "Requirement already satisfied, skipping upgrade: beautifulsoup4 in /home/eddypermana22/.local/lib/python3.8/site-packages (from wikipedia) (4.12.2)\n",
    "Requirement already satisfied, skipping upgrade: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.8)\n",
    "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2019.11.28)\n",
    "Requirement already satisfied, skipping upgrade: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.25.8)\n",
    "Requirement already satisfied, skipping upgrade: charset-normalizer<4,>=2 in /home/eddypermana22/.local/lib/python3.8/site-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.2.0)\n",
    "Requirement already satisfied, skipping upgrade: soupsieve>1.2 in /home/eddypermana22/.local/lib/python3.8/site-packages (from beautifulsoup4->wikipedia) (2.4.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddf726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools, initialize_agent\n",
    "from langchain.agents import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2089c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c7d320",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cd23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent(\"What is the 25% of 300?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26774980",
   "metadata": {},
   "outputs": [],
   "source": [
    "[chain/start] [1:chain:AgentExecutor] Entering Chain run with input:\n",
    "{\n",
    "  \"input\": \"What is the 25% of 300?\"\n",
    "}\n",
    "[chain/start] [1:chain:AgentExecutor > 2:chain:LLMChain] Entering Chain run with input:\n",
    "{\n",
    "  \"input\": \"What is the 25% of 300?\",\n",
    "  \"agent_scratchpad\": \"\",\n",
    "  \"stop\": [\n",
    "    \"Observation:\"\n",
    "  ]\n",
    "}\n",
    "[llm/start] [1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
    "{\n",
    "  \"prompts\": [\n",
    "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: What is the 25% of 300?\"\n",
    "  ]\n",
    "}\n",
    "[llm/end] [1:chain:AgentExecutor > 2:chain:LLMChain > 3:llm:ChatOpenAI] [8.36s] Exiting LLM run with output:\n",
    "{\n",
    "  \"generations\": [\n",
    "    [\n",
    "      {\n",
    "        \"text\": \"Thought: To find 25% of 300, I need to multiply 300 by 0.25. I can use the calculator tool for this.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"300 * 0.25\\\"\\n}\\n```\",\n",
    "        \"generation_info\": {\n",
    "          \"finish_reason\": \"stop\"\n",
    "        },\n",
    "        \"message\": {\n",
    "          \"lc\": 1,\n",
    "          \"type\": \"constructor\",\n",
    "          \"id\": [\n",
    "            \"langchain\",\n",
    "            \"schema\",\n",
    "            \"messages\",\n",
    "            \"AIMessage\"\n",
    "          ],\n",
    "          \"kwargs\": {\n",
    "            \"content\": \"Thought: To find 25% of 300, I need to multiply 300 by 0.25. I can use the calculator tool for this.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"300 * 0.25\\\"\\n}\\n```\",\n",
    "            \"additional_kwargs\": {}\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  ],\n",
    "  \"llm_output\": {\n",
    "    \"token_usage\": {\n",
    "      \"prompt_tokens\": 273,\n",
    "      \"completion_tokens\": 59,\n",
    "      \"total_tokens\": 332\n",
    "    },\n",
    "    \"model_name\": \"gpt-4\"\n",
    "  },\n",
    "  \"run\": null\n",
    "}\n",
    "[chain/end] [1:chain:AgentExecutor > 2:chain:LLMChain] [8.36s] Exiting Chain run with output:\n",
    "{\n",
    "  \"text\": \"Thought: To find 25% of 300, I need to multiply 300 by 0.25. I can use the calculator tool for this.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"300 * 0.25\\\"\\n}\\n```\"\n",
    "}\n",
    "[tool/start] [1:chain:AgentExecutor > 4:tool:Calculator] Entering Tool run with input:\n",
    "\"300 * 0.25\"\n",
    "[chain/start] [1:chain:AgentExecutor > 4:tool:Calculator > 5:chain:LLMMathChain] Entering Chain run with input:\n",
    "{\n",
    "  \"question\": \"300 * 0.25\"\n",
    "}\n",
    "[chain/start] [1:chain:AgentExecutor > 4:tool:Calculator > 5:chain:LLMMathChain > 6:chain:LLMChain] Entering Chain run with input:\n",
    "{\n",
    "  \"question\": \"300 * 0.25\",\n",
    "  \"stop\": [\n",
    "    \"```output\"\n",
    "  ]\n",
    "}\n",
    "[llm/start] [1:chain:AgentExecutor > 4:tool:Calculator > 5:chain:LLMMathChain > 6:chain:LLMChain > 7:llm:ChatOpenAI] Entering LLM run with input:\n",
    "{\n",
    "  \"prompts\": [\n",
    "    \"Human: Translate a math problem into a expression that can be executed using Python's numexpr library. Use the output of running this code to answer the question.\\n\\nQuestion: ${Question with math problem.}\\n```text\\n${single line mathematical expression that solves the problem}\\n```\\n...numexpr.evaluate(text)...\\n```output\\n${Output of running the code}\\n```\\nAnswer: ${Answer}\\n\\nBegin.\\n\\nQuestion: What is 37593 * 67?\\n```text\\n37593 * 67\\n```\\n...numexpr.evaluate(\\\"37593 * 67\\\")...\\n```output\\n2518731\\n```\\nAnswer: 2518731\\n\\nQuestion: 37593^(1/5)\\n```text\\n37593**(1/5)\\n```\\n...numexpr.evaluate(\\\"37593**(1/5)\\\")...\\n```output\\n8.222831614237718\\n```\\nAnswer: 8.222831614237718\\n\\nQuestion: 300 * 0.25\"\n",
    "  ]\n",
    "}\n",
    "[llm/end] [1:chain:AgentExecutor > 4:tool:Calculator > 5:chain:LLMMathChain > 6:chain:LLMChain > 7:llm:ChatOpenAI] [3.35s] Exiting LLM run with output:\n",
    "{\n",
    "  \"generations\": [\n",
    "    [\n",
    "      {\n",
    "        \"text\": \"```text\\n300 * 0.25\\n```\\n...numexpr.evaluate(\\\"300 * 0.25\\\")...\\n\",\n",
    "        \"generation_info\": {\n",
    "          \"finish_reason\": \"stop\"\n",
    "        },\n",
    "        \"message\": {\n",
    "          \"lc\": 1,\n",
    "          \"type\": \"constructor\",\n",
    "          \"id\": [\n",
    "            \"langchain\",\n",
    "            \"schema\",\n",
    "            \"messages\",\n",
    "            \"AIMessage\"\n",
    "          ],\n",
    "          \"kwargs\": {\n",
    "            \"content\": \"```text\\n300 * 0.25\\n```\\n...numexpr.evaluate(\\\"300 * 0.25\\\")...\\n\",\n",
    "            \"additional_kwargs\": {}\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  ],\n",
    "  \"llm_output\": {\n",
    "    \"token_usage\": {\n",
    "      \"prompt_tokens\": 206,\n",
    "      \"completion_tokens\": 25,\n",
    "      \"total_tokens\": 231\n",
    "    },\n",
    "    \"model_name\": \"gpt-4\"\n",
    "  },\n",
    "  \"run\": null\n",
    "}\n",
    "[chain/end] [1:chain:AgentExecutor > 4:tool:Calculator > 5:chain:LLMMathChain > 6:chain:LLMChain] [3.35s] Exiting Chain run with output:\n",
    "{\n",
    "  \"text\": \"```text\\n300 * 0.25\\n```\\n...numexpr.evaluate(\\\"300 * 0.25\\\")...\\n\"\n",
    "}\n",
    "[chain/end] [1:chain:AgentExecutor > 4:tool:Calculator > 5:chain:LLMMathChain] [3.35s] Exiting Chain run with output:\n",
    "{\n",
    "  \"answer\": \"Answer: 75.0\"\n",
    "}\n",
    "[tool/end] [1:chain:AgentExecutor > 4:tool:Calculator] [3.35s] Exiting Tool run with output:\n",
    "\"Answer: 75.0\"\n",
    "[chain/start] [1:chain:AgentExecutor > 8:chain:LLMChain] Entering Chain run with input:\n",
    "{\n",
    "  \"input\": \"What is the 25% of 300?\",\n",
    "  \"agent_scratchpad\": \"This was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: To find 25% of 300, I need to multiply 300 by 0.25. I can use the calculator tool for this.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"300 * 0.25\\\"\\n}\\n```\\nObservation: Answer: 75.0\\nThought:\",\n",
    "  \"stop\": [\n",
    "    \"Observation:\"\n",
    "  ]\n",
    "}\n",
    "[llm/start] [1:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] Entering LLM run with input:\n",
    "{\n",
    "  \"prompts\": [\n",
    "    \"System: Answer the following questions as best you can. You have access to the following tools:\\n\\nCalculator: Useful for when you need to answer questions about math.\\n\\nThe way you use the tools is by specifying a json blob.\\nSpecifically, this json should have a `action` key (with the name of the tool to use) and a `action_input` key (with the input to the tool going here).\\n\\nThe only values that should be in the \\\"action\\\" field are: Calculator\\n\\nThe $JSON_BLOB should only contain a SINGLE action, do NOT return a list of multiple actions. Here is an example of a valid $JSON_BLOB:\\n\\n```\\n{\\n  \\\"action\\\": $TOOL_NAME,\\n  \\\"action_input\\\": $INPUT\\n}\\n```\\n\\nALWAYS use the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction:\\n```\\n$JSON_BLOB\\n```\\nObservation: the result of the action\\n... (this Thought/Action/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin! Reminder to always use the exact characters `Final Answer` when responding.\\nHuman: What is the 25% of 300?\\n\\nThis was your previous work (but I haven't seen any of it! I only see what you return as final answer):\\nThought: To find 25% of 300, I need to multiply 300 by 0.25. I can use the calculator tool for this.\\nAction:\\n```\\n{\\n  \\\"action\\\": \\\"Calculator\\\",\\n  \\\"action_input\\\": \\\"300 * 0.25\\\"\\n}\\n```\\nObservation: Answer: 75.0\\nThought:\"\n",
    "  ]\n",
    "}\n",
    "[llm/end] [1:chain:AgentExecutor > 8:chain:LLMChain > 9:llm:ChatOpenAI] [3.19s] Exiting LLM run with output:\n",
    "{\n",
    "  \"generations\": [\n",
    "    [\n",
    "      {\n",
    "        \"text\": \"The calculator tool has correctly calculated 25% of 300 as 75.\\nFinal Answer: 25% of 300 is 75.\",\n",
    "        \"generation_info\": {\n",
    "          \"finish_reason\": \"stop\"\n",
    "        },\n",
    "        \"message\": {\n",
    "          \"lc\": 1,\n",
    "          \"type\": \"constructor\",\n",
    "          \"id\": [\n",
    "            \"langchain\",\n",
    "            \"schema\",\n",
    "            \"messages\",\n",
    "            \"AIMessage\"\n",
    "          ],\n",
    "          \"kwargs\": {\n",
    "            \"content\": \"The calculator tool has correctly calculated 25% of 300 as 75.\\nFinal Answer: 25% of 300 is 75.\",\n",
    "            \"additional_kwargs\": {}\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ]\n",
    "  ],\n",
    "  \"llm_output\": {\n",
    "    \"token_usage\": {\n",
    "      \"prompt_tokens\": 370,\n",
    "      \"completion_tokens\": 29,\n",
    "      \"total_tokens\": 399\n",
    "    },\n",
    "    \"model_name\": \"gpt-4\"\n",
    "  },\n",
    "  \"run\": null\n",
    "}\n",
    "[chain/end] [1:chain:AgentExecutor > 8:chain:LLMChain] [3.19s] Exiting Chain run with output:\n",
    "{\n",
    "  \"text\": \"The calculator tool has correctly calculated 25% of 300 as 75.\\nFinal Answer: 25% of 300 is 75.\"\n",
    "}\n",
    "[chain/end] [1:chain:AgentExecutor] [14.90s] Exiting Chain run with output:\n",
    "{\n",
    "  \"output\": \"25% of 300 is 75.\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f14910",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'input': 'What is the 25% of 300?', 'output': '25% of 300 is 75.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7a238",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Tom M. Mitchell is an American computer scientist \\\n",
    "and the Founders University Professor at Carnegie Mellon University (CMU)\\\n",
    "what book did he write?\"\n",
    "\n",
    "result = agent(question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67cde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "Thought: I need to look up information about Tom M. Mitchell and the book he wrote. However, I don't have a tool that can help me with this task. I can only use a calculator and a time tool, which are not useful in this case. \n",
    "\n",
    "Final Answer: I'm sorry, but I can't provide the information you're looking for.\n",
    "\n",
    "> Finished chain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a569cfe",
   "metadata": {},
   "source": [
    "# Python Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b3a8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.agent_toolkits import create_python_agent\n",
    "from langchain.tools.python.tool import PythonREPLTool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac20bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_python_agent(\n",
    "    llm,\n",
    "    tool=PythonREPLTool(),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b18f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = [\"10\", \"20\", \"30\", \"40\", \"50\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bab5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(f\"\"\"sum all the number \\\n",
    "and print the output: {numbers}\"\"\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17a5d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "The input is a list of strings, each representing a number. To find the sum, I need to convert each string to an integer, then use the built-in `sum` function. I will write a list comprehension to convert the strings to integers, then pass the result to `sum`. I will print the result to observe it. \n",
    "Action: Python_REPL\n",
    "Action Input: numbers = ['10', '20', '30', '40', '50']\n",
    "numbers = [int(num) for num in numbers]\n",
    "total = sum(numbers)\n",
    "print(total)\n",
    "Observation: 150\n",
    "\n",
    "Thought:I have successfully calculated the sum of the numbers in the list.\n",
    "Final Answer: 150\n",
    "\n",
    "> Finished chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac64e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "'150'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167420f9",
   "metadata": {},
   "source": [
    "# Custom-made Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e1041",
   "metadata": {},
   "source": [
    "LangChain users can create their custom-made tools through the tool decorator and connect their agent to their preferred data sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6e57e1",
   "metadata": {},
   "source": [
    "An example of a custom-made tool can be a function that returns the current date. The function is added to the agent’s list of tools, and when asked, the agent can accurately tell the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c23836",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install DateTime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01e5d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "Requirement already satisfied: DateTime in /home/eddypermana22/.local/lib/python3.8/site-packages (5.2)\n",
    "Requirement already satisfied: zope.interface in /usr/lib/python3/dist-packages (from DateTime) (4.7.1)\n",
    "Requirement already satisfied: pytz in /home/eddypermana22/.local/lib/python3.8/site-packages (from DateTime) (2023.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef0a96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dfee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def time(text: str) -> str:\n",
    "    \"\"\"Returns todays date, use this for any \\\n",
    "    questions related to knowing todays date. \\\n",
    "    The input should always be an empty string, \\\n",
    "    and this function will always return todays \\\n",
    "    date - any date mathmatics should occur \\\n",
    "    outside this function.\"\"\"\n",
    "    return str(date.today())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363e9076",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent= initialize_agent(\n",
    "    tools + [time], \n",
    "    llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1933c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(f\"\"\"What date is tomorrow?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a43b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "> Entering new AgentExecutor chain...\n",
    "Thought: I need to know today's date first, then add one day to it to get tomorrow's date. I can use the 'time' tool to get today's date.\n",
    "Action:\n",
    "```\n",
    "{\n",
    "  \"action\": \"time\",\n",
    "  \"action_input\": \"\"\n",
    "}\n",
    "```\n",
    "Observation: 2023-08-03\n",
    "Thought:Now that I know today's date, I need to add one day to it to get tomorrow's date. However, I don't have a tool that can add days to a date. I'll have to do this manually. Since today is the 3rd of August, 2023, adding one day would make it the 4th of August, 2023.\n",
    "Thought: I now know the final answer.\n",
    "Final Answer: The date tomorrow is 2023-08-04.\n",
    "\n",
    "> Finished chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033a94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'The date tomorrow is 2023-08-04.'"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
