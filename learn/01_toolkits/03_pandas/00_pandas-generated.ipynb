{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9ad804",
   "metadata": {},
   "source": [
    "source: [link](https://ai-bootcamp.ruangguru.com/learn/01_toolkits/03_pandas/00_pandas.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9588379",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f1098f",
   "metadata": {},
   "source": [
    "# What is Pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9b01ab",
   "metadata": {},
   "source": [
    "Pandas is a popular open-source data analysis and manipulation library, built on top of the Python programming language. It provides flexible and efficient data structures that make it easier to handle and analyze data. Pandas is particularly well-suited for structured or tabular data, such as CSV and Excel files, SQL databases, or dataframes in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931e1973",
   "metadata": {},
   "source": [
    "# Why use Pandas for Data Engineering?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ac3ebc",
   "metadata": {},
   "source": [
    "Data Handling: Pandas can handle a variety of data sets in different formats - CSV files, Excel files, or database records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fbe1a8",
   "metadata": {},
   "source": [
    "Ease of Use: With only a few lines of code, Pandas makes it easy for users to read, write, and modify datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41af45c",
   "metadata": {},
   "source": [
    "Data Transformation: It offers robust tools for cleaning and pivoting data, preparing it for analysis or visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8545853",
   "metadata": {},
   "source": [
    "Efficient Operations: Pandas is built on top of NumPy, a Python library for numerical computation, which makes it efficient for performing operations on large datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc0066",
   "metadata": {},
   "source": [
    "Integration: It integrates well with many other libraries in the scientific Python ecosystem, such as Matplotlib for plotting graphs, Scikit-learn for machine learning, and many others."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4223c747",
   "metadata": {},
   "source": [
    "# Installing Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e60b40",
   "metadata": {},
   "source": [
    "Pandas can be installed in your Python environment using package managers like pip or conda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365b5719",
   "metadata": {},
   "source": [
    "# Installing Pandas using pip:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53eabb85",
   "metadata": {},
   "source": [
    "If you’re using a Jupyter notebook, you can install it using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e8b9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c869d4",
   "metadata": {},
   "source": [
    "For installation on your system, you can use pip in your command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1405b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a4e939",
   "metadata": {},
   "source": [
    "# Installing Pandas using conda:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3f82a7",
   "metadata": {},
   "source": [
    "If you are using the Anaconda distribution of Python, you can use the conda package manager to install pandas. Type the following command in your terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53035bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651de4ba",
   "metadata": {},
   "source": [
    "After installation, you can import and check the installed Pandas version in your Python script as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b90314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7702ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.5.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd97308",
   "metadata": {},
   "source": [
    "This will print the version of Pandas installed in your environment to ensure it’s correctly installed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532e7c88",
   "metadata": {},
   "source": [
    "# Pandas Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866e0280",
   "metadata": {},
   "source": [
    "# Pandas Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d251d6f6",
   "metadata": {},
   "source": [
    "What is a Series? A Series is a one-dimensional labeled array that can hold any data type. It is similar to a column in a spreadsheet or a vector in a mathematical matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f91523",
   "metadata": {},
   "source": [
    "# Key Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a9a823",
   "metadata": {},
   "source": [
    "# Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73fd95",
   "metadata": {},
   "source": [
    "What is a DataFrame? A DataFrame is a 2-dimensional labeled data structure in Pandas, similar to a table in a relational database, an Excel spreadsheet, or a dictionary of Series objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebd5e3",
   "metadata": {},
   "source": [
    "Here is a basic example of a DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c2c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter'],\n",
    "    'Age': [28, 23, 34]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9bc69a",
   "metadata": {},
   "source": [
    "|  | Name | Age |\n",
    "| --- | --- | --- |\n",
    "| 0 | John | 28 |\n",
    "| 1 | Anna | 23 |\n",
    "| 2 | Peter | 34 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa7f6214",
   "metadata": {},
   "source": [
    "In this example, ‘Name’ and ‘Age’ are column labels and the numbers 0, 1, 2 on the left are the index labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37efba5",
   "metadata": {},
   "source": [
    "An index in Pandas is a built-in data structure that makes data manipulation and analysis more efficient. It is an immutable array (cannot be changed) and an ordered set. By default Pandas uses a numeric sequence starting from 0 as index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b49441",
   "metadata": {},
   "source": [
    "If you want to customize these index labels, you can do so when creating the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fceda6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data, index=['a', 'b', 'c'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80411114",
   "metadata": {},
   "source": [
    "|  | Name | Age |\n",
    "| --- | --- | --- |\n",
    "| a | John | 28 |\n",
    "| b | Anna | 23 |\n",
    "| c | Peter | 34 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5455bf88",
   "metadata": {},
   "source": [
    "Now, ‘a’, ‘b’, ‘c’ are the index labels. These can be used with loc method to access specific rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e3f497",
   "metadata": {},
   "source": [
    "# Key Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f08196",
   "metadata": {},
   "source": [
    "# Why is it Useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7f7e9",
   "metadata": {},
   "source": [
    "# Basic Operations with Series and DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b513053",
   "metadata": {},
   "source": [
    "# Creating a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70915aef",
   "metadata": {},
   "source": [
    "You can create a Series from dictionaries, ndarrays, and scalar values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebde8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# From a dictionary\n",
    "s1 = pd.Series({'a': 0, 'b': 1, 'c': 2})\n",
    "print(s1)\n",
    "\n",
    "# From an ndarray\n",
    "s2 = pd.Series(['a', 'b', 'c', 'd'])\n",
    "print(s2)\n",
    "\n",
    "# From a scalar\n",
    "s3 = pd.Series(5, index=[0, 1, 2, 3])\n",
    "print(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00eb20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a    0\n",
    "b    1\n",
    "c    2\n",
    "dtype: int64\n",
    "0    a\n",
    "1    b\n",
    "2    c\n",
    "3    d\n",
    "dtype: object\n",
    "0    5\n",
    "1    5\n",
    "2    5\n",
    "3    5\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca0a138",
   "metadata": {},
   "source": [
    "# Indexing a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a021b93d",
   "metadata": {},
   "source": [
    "You can access the elements of a Series in a similar way to indexing with native Python data structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abd00db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series(['a', 'b', 'c', 'd'])\n",
    "\n",
    "# Accessing a single element using its index\n",
    "print(s[0])\n",
    "\n",
    "# Accessing multiple elements using their indices\n",
    "print(s[[0, 1, 2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b13686",
   "metadata": {},
   "outputs": [],
   "source": [
    "a\n",
    "0    a\n",
    "1    b\n",
    "2    c\n",
    "dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903419ef",
   "metadata": {},
   "source": [
    "# Slicing a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f6439",
   "metadata": {},
   "source": [
    "Slicing a Series in pandas works in a similar way to slicing in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d6a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "s = pd.Series([1, 2, 3, 4, 5], index=['a', 'b', 'c', 'd', 'e'])\n",
    "print(s)\n",
    "\n",
    "# Slice using the index values (explicit index) - Here 'end' value is included\n",
    "print(s['a':'c'])\n",
    "\n",
    "# Slice using index numbers (implicit index) - Here 'end' value is excluded\n",
    "print(s[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cdcb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "d    4\n",
    "e    5\n",
    "dtype: int64\n",
    "a    1\n",
    "b    2\n",
    "c    3\n",
    "dtype: int64\n",
    "a    1\n",
    "b    2\n",
    "dtype: int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fda18c",
   "metadata": {},
   "source": [
    "Remember that when using explicit index (labels ‘a’, ‘b’, ‘c’, etc.), the slice includes the end index - that’s why ‘c’ is included in the result. While when using implicit index, the ‘end’ index is not included in the slice - so the 2nd index (which is ‘c’ and is the third element) is not included."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999fa63a",
   "metadata": {},
   "source": [
    "# Creating a DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07895f4",
   "metadata": {},
   "source": [
    "You can create a DataFrame from various data types: dictionary, list of lists, list of dictionaries etc. In data engineering, creating a DataFrame is the first step before performing any data manipulation or analysis tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd282ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating DataFrame\n",
    "data = {\n",
    "    'Name': ['John', 'Anna', 'Peter'],\n",
    "    'Age': [25, 23, 31],\n",
    "    'Nationality': [\"UK\", \"USA\", \"UK\"]\n",
    "}\n",
    "df = pd.DataFrame(data, index=['a', 'b', 'c'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02684c0a",
   "metadata": {},
   "source": [
    "|  | Name | Age | Nationality |\n",
    "| --- | --- | --- | --- |\n",
    "| a | John | 25 | UK |\n",
    "| b | Anna | 23 | USA |\n",
    "| c | Peter | 31 | UK |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0fe5f0",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763b123c",
   "metadata": {},
   "source": [
    "Indexing is the process of accessing an element in a sequence using its position in the sequence (its index). In Pandas, indexing refers to accessing rows and columns of data from a DataFrame, whereas slicing refers to accessing a range of rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0bf31",
   "metadata": {},
   "source": [
    "We can access data or range of data from a DataFrame using different methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f14aaf",
   "metadata": {},
   "source": [
    "# Using column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7286c5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing 'Name' column\n",
    "names = df['Name']\n",
    "print('- \"Name\" column:')\n",
    "print(names)\n",
    "\n",
    "# Accessing multiple columns\n",
    "subset = df[['Name', 'Nationality']]\n",
    "print('- multiple columns:')\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f11bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "- \"Name\" column:\n",
    "a     John\n",
    "b     Anna\n",
    "c    Peter\n",
    "Name: Name, dtype: object\n",
    "- multiple columns:\n",
    "    Name Nationality\n",
    "a   John          UK\n",
    "b   Anna         USA\n",
    "c  Peter          UK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746ea709",
   "metadata": {},
   "source": [
    "# Using .loc and .iloc:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346f01e",
   "metadata": {},
   "source": [
    "Pandas provides various methods to index and access data in a DataFrame, including .loc and .iloc. These methods are used to access a group of rows and columns by labels or a boolean array."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2842de11",
   "metadata": {},
   "source": [
    ".loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd798213",
   "metadata": {},
   "source": [
    "loc is a label-based data selection method which means that we have to pass the name of the row or column which we want to select. This method includes the last element of the range, unlike Python and iloc method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing a single row\n",
    "print('- single row:')\n",
    "print(df.loc['a'])\n",
    "\n",
    "# Accessing multiple rows\n",
    "print('- multiple row:')\n",
    "print(df.loc[['a', 'b']])\n",
    "\n",
    "# Accessing rows and specific columns\n",
    "print('- rows and specific columns:')\n",
    "print(df.loc[['a', 'b'], 'Name'])\n",
    "\n",
    "# Accessing all rows and specific columns\n",
    "print('- all rows and specific columns:')\n",
    "print(df.loc[:, 'Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d264d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "- single row:\n",
    "Name           John\n",
    "Age              25\n",
    "Nationality      UK\n",
    "Name: a, dtype: object\n",
    "- multiple row:\n",
    "   Name  Age Nationality\n",
    "a  John   25          UK\n",
    "b  Anna   23         USA\n",
    "- rows and specific columns:\n",
    "a    John\n",
    "b    Anna\n",
    "Name: Name, dtype: object\n",
    "- all rows and specific columns:\n",
    "a     John\n",
    "b     Anna\n",
    "c    Peter\n",
    "Name: Name, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3af721",
   "metadata": {},
   "source": [
    ".iloc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e76e5",
   "metadata": {},
   "source": [
    "iloc is an integer index-based method which means that we have to pass integer index in the method to select specific rows/columns. This method does not include the last element of the range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac184595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accessing first row\n",
    "print('- first row:')\n",
    "print(df.iloc[0])\n",
    "\n",
    "# Accessing first and second rows\n",
    "print('- first and second rows:')\n",
    "print(df.iloc[0:2])\n",
    "\n",
    "# Accessing first row and first column\n",
    "print('- first row and first column:')\n",
    "print(df.iloc[0, 0])\n",
    "\n",
    "# Accessing all rows and first column\n",
    "print('- all rows and first column:')\n",
    "print(df.iloc[:, 0])\n",
    "\n",
    "# Accessing first two rows and first two columns\n",
    "print('- first two rows and first two columns:')\n",
    "print(df.iloc[0:2, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c9cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "- first row:\n",
    "Name           John\n",
    "Age              25\n",
    "Nationality      UK\n",
    "Name: a, dtype: object\n",
    "- first and second rows:\n",
    "   Name  Age Nationality\n",
    "a  John   25          UK\n",
    "b  Anna   23         USA\n",
    "- first row and first column:\n",
    "John\n",
    "- all rows and first column:\n",
    "a     John\n",
    "b     Anna\n",
    "c    Peter\n",
    "Name: Name, dtype: object\n",
    "- first two rows and first two columns:\n",
    "   Name  Age\n",
    "a  John   25\n",
    "b  Anna   23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da2a343",
   "metadata": {},
   "source": [
    "# Slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a465c8",
   "metadata": {},
   "source": [
    "Slicing is used to access a sequence of data in the dataframe. Slicing is often used in data engineering to divide the dataset into smaller chunks for further processing, for example, dividing the data into train and test sets for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78808810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice the first three rows\n",
    "first_three_rows = df[:3]\n",
    "print(first_three_rows)\n",
    "\n",
    "# Slice rows from index 1 to 3\n",
    "subset = df[1:4]\n",
    "print(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53714530",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Name  Age Nationality\n",
    "a   John   25          UK\n",
    "b   Anna   23         USA\n",
    "c  Peter   31          UK\n",
    "    Name  Age Nationality\n",
    "b   Anna   23         USA\n",
    "c  Peter   31          UK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2132d5f",
   "metadata": {},
   "source": [
    "# Filtering Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34712d89",
   "metadata": {},
   "source": [
    "Filtering in Pandas allows you to select rows that satisfy a certain condition. You can use slicing with boolean indexing for this. Boolean indexing uses a boolean vector to filter the data. The boolean vector is generated by applying a logical condition to the data. The rows corresponding to True in the boolean vector are selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aa3a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Age' is greater than 30\n",
    "age_above_30 = df[df['Age'] > 30]\n",
    "\n",
    "print(age_above_30.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e5e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Name  Age Nationality\n",
    "c  Peter   31          UK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce270b87",
   "metadata": {},
   "source": [
    "You can also combine multiple conditions using the & (and) and | (or) operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88de3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where 'Age' is greater than 30 and 'Paying_Status' is 'Paid'\n",
    "age_above_30_and_teacher = df[(df['Age'] > 30) & (df['Nationality'] == 'UK')]\n",
    "print(age_above_30_and_teacher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5775d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    Name  Age Nationality\n",
    "c  Peter   31          UK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14f2058",
   "metadata": {},
   "source": [
    "Remember, when combining conditions, you need to put each condition in parentheses. This is because the & and | operators have higher precedence than the comparison operators like > and ==."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7c51f6",
   "metadata": {},
   "source": [
    "# Data Import and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed40bbf3",
   "metadata": {},
   "source": [
    "Indexing is useful in data engineering to access specific parts of the data for further operations like transformations, calculations etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd43559a",
   "metadata": {},
   "source": [
    "# Reading Data From CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c67ef6",
   "metadata": {},
   "source": [
    "Reading data from a CSV file is an important task in data engineering and data science. It’s usually the first step when we have to analyze data which is stored in CSV format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fabab36",
   "metadata": {},
   "source": [
    "Many programming languages provide libraries to read data from CSV files. For instance, in Python, we use libraries like pandas to read CSV data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099ea214",
   "metadata": {},
   "source": [
    "Here is a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb7a156",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load the data\n",
    "dataframe = pd.read_csv('https://storage.googleapis.com/rg-ai-bootcamp/pandas/import-data.csv')\n",
    "\n",
    "# print the first few lines of the dataframe\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d47c30",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.0 | C10 | S |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.5 | E25 | C |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.0 | G12 | Q |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.0 | A5 | S |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.0 | B15 | S |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ced14f",
   "metadata": {},
   "source": [
    "In this example, the read_csv() function reads a CSV file and converts it into a Pandas DataFrame. dataframe.head() then prints the first 5 rows of the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8356679",
   "metadata": {},
   "source": [
    "Considerations while reading CSVs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043958d9",
   "metadata": {},
   "source": [
    "Delimiter: A CSV file’s default delimiter is a comma. However, other characters like semicolons can be used. The correct delimiter should be specified when reading a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a85ae7b",
   "metadata": {},
   "source": [
    "Header: If the first line of the CSV file is a header (names of columns), make sure the library correctly identifies it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560238d4",
   "metadata": {},
   "source": [
    "Encoding: CSV files can be written in different encodings. If you encounter a UnicodeDecodeError, you might need to specify the correct encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2709017c",
   "metadata": {},
   "source": [
    "# Writing Data To CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42d760a",
   "metadata": {},
   "source": [
    "We often need to write or export data to a CSV file after manipulating or analyzing it. This written data can then be used in other systems, shared with other teams, or merely stored for future use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570b9a14",
   "metadata": {},
   "source": [
    "Here is a simple Python example of writing data to a CSV file using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a simple dataframe\n",
    "new_dataframe = pd.DataFrame({\n",
    "   'PassengerId': [1, 2, 3],\n",
    "   'class': ['First', 'Second', 'First'],\n",
    "   'sex': ['Female', 'Male', 'Male'],\n",
    "   'age': [28, 24, 35],\n",
    "   'ticket': ['U64297', 'V91254', 'W72311'],\n",
    "   'fare': [75.40, 50.00, 100.00],\n",
    "   'cabin': ['C20', 'A1', 'Z5'],\n",
    "   'embarked': ['S', 'Q', 'S']\n",
    "})\n",
    "\n",
    "# write to a CSV file\n",
    "new_dataframe.to_csv('./data/export-data.csv', index=False)\n",
    "\n",
    "# print the dataframe\n",
    "new_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f55f14",
   "metadata": {},
   "source": [
    "|  | PassengerId | class | sex | age | ticket | fare | cabin | embarked |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Female | 28 | U64297 | 75.4 | C20 | S |\n",
    "| 1 | 2 | Second | Male | 24 | V91254 | 50.0 | A1 | Q |\n",
    "| 2 | 3 | First | Male | 35 | W72311 | 100.0 | Z5 | S |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677e14ce",
   "metadata": {},
   "source": [
    "In this case, the to_csv() function writes the DataFrame to a CSV file. The index=False argument prevents pandas from writing row indices into the CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e6add3",
   "metadata": {},
   "source": [
    "Considerations while writing CSVs:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f93d631",
   "metadata": {},
   "source": [
    "Delimiter: While a comma is standard, you might need to use a different character as a delimiter, which can be defined when writing a CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94269cd",
   "metadata": {},
   "source": [
    "Header: You can choose to include or exclude the header in your CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718e5648",
   "metadata": {},
   "source": [
    "Encoding: You can specify the type of encoding for your CSV file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39bc9314",
   "metadata": {},
   "source": [
    "These functionalities to read and write CSV files form the basics of handling data in data engineering or data science tasks. They enable you to ingest data from various sources, process it as needed, and store or distribute results in a universally accepted format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc806d2a",
   "metadata": {},
   "source": [
    "# Data Indexing and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91887a25",
   "metadata": {},
   "source": [
    "Data indexing and selection is a crucial aspect of data manipulation and analysis. It allows us to access specific subsets of data efficiently. This process is particularly important when dealing with large datasets where manual inspection is not feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23cef7d",
   "metadata": {},
   "source": [
    "# Selecting Data by Index, Columns, and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9daaa49",
   "metadata": {},
   "source": [
    "In Pandas, a popular data manipulation library in Python, you can select data based on the following 3 things: - Index - Columns - Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae7e88",
   "metadata": {},
   "source": [
    "First, you need to import the necessary libraries and load your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61389eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the .csv file\n",
    "dataframe = pd.read_csv('https://storage.googleapis.com/rg-ai-bootcamp/pandas/import-data.csv')\n",
    "\n",
    "dataframe.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eb3c1e",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.00 | C10 | S |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.50 | E25 | C |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1100d",
   "metadata": {},
   "source": [
    "# Selecting Data by Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3bfbb",
   "metadata": {},
   "source": [
    "The iloc function is used to select data by its numeric index, similar to how we access elements in a list. The i in iloc stands for integer. We can select a single row, or multiple rows, or even cut a range of rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bcc636",
   "metadata": {},
   "source": [
    "For example, here we want to see in detail the data from the first row, we can access it via index (index = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4d3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first row\n",
    "first_row = dataframe.iloc[0]\n",
    "\n",
    "first_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c1353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "passengerId         1\n",
    "class           First\n",
    "sex              Male\n",
    "age                32\n",
    "ticket         A12345\n",
    "fare             50.0\n",
    "cabin             C10\n",
    "embarked            S\n",
    "Name: 0, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73600b69",
   "metadata": {},
   "source": [
    "# Selecting Data by Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a265f2c",
   "metadata": {},
   "source": [
    "We can select data by its column name in Pandas using the [] operator. This will return a Series object containing the data in the specified column. In this case, we want to look based on class in the data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b52e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the 'embarked' column\n",
    "class_column = dataframe['class']\n",
    "\n",
    "class_column.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1952b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "0     First\n",
    "1    Second\n",
    "2     Third\n",
    "3     First\n",
    "4    Second\n",
    "5     Third\n",
    "6     First\n",
    "7    Second\n",
    "8     Third\n",
    "9     First\n",
    "Name: class, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ad81bf",
   "metadata": {},
   "source": [
    "# Selecting Data by Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92657267",
   "metadata": {},
   "source": [
    "The loc function in Pandas is used to select rows based on their labels. In a DataFrame, row labels are indexes. By default, DataFrame indexes are numeric, similar to list indexes. However, we can set the index to be any column of the DataFrame, which allows us to use loc to select rows based on the values in that column. After we know the passenger class through the class column, now we want to see more detailed passenger data from the first class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de82af0",
   "metadata": {},
   "source": [
    "We can use the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7992d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the 'class' column as the index\n",
    "dataframe.set_index('class', inplace=True)\n",
    "\n",
    "# Select the row with the label 'First'\n",
    "first_row = dataframe.loc['First']\n",
    "\n",
    "first_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038b3c9e",
   "metadata": {},
   "source": [
    "|  | passengerId | sex | age | ticket | fare | cabin | embarked |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| class |  |  |  |  |  |  |  |\n",
    "| First | 1 | Male | 32 | A12345 | 50.0 | C10 | S |\n",
    "| First | 4 | Female | 40 | D13579 | 100.0 | A5 | S |\n",
    "| First | 7 | Male | 50 | G75319 | 80.5 | D8 | C |\n",
    "| First | 10 | Female | 45 | J86420 | 90.0 | G5 | C |\n",
    "| First | 13 | Male | 55 | M75319 | 75.5 | C8 | S |\n",
    "| First | 16 | Female | 38 | P86420 | 95.0 | F5 | S |\n",
    "| First | 19 | Male | 60 | S75319 | 70.5 | I8 | C |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8baa832",
   "metadata": {},
   "source": [
    "# Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a5e84a",
   "metadata": {},
   "source": [
    "# Adding and Updating Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f91c6",
   "metadata": {},
   "source": [
    "# Adding Column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeaae67",
   "metadata": {},
   "source": [
    "You can add a new column to your DataFrame in several ways: 1. Assigning a scalar value to a new column 2. Adding a Series as a new column 3. Adding a calculated column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b67255",
   "metadata": {},
   "source": [
    "First, you need to import the necessary libraries and load your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3f8b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from the .csv file\n",
    "passenger_df = pd.read_csv('https://storage.googleapis.com/rg-ai-bootcamp/pandas/import-data.csv')\n",
    "\n",
    "passenger_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a9b1de",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.00 | C10 | S |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.50 | E25 | C |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54ce650",
   "metadata": {},
   "source": [
    "# 1. Assigning a scalar value to a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02fdf37",
   "metadata": {},
   "source": [
    "This will add a new column to our DataFrame with the supplied scalar values for all the rows. For example, we want to add a column for the discount given to all passengers of 0.15. We can add it in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de875c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column in df\n",
    "passenger_df['discount'] = 0.15\n",
    "\n",
    "passenger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9310e388",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked | discount |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.0 | C10 | S | 0.15 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.5 | E25 | C | 0.15 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.0 | G12 | Q | 0.15 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.0 | A5 | S | 0.15 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.0 | B15 | S | 0.15 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8ae6ba",
   "metadata": {},
   "source": [
    "# 2. Adding a Series as a new column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a6791c",
   "metadata": {},
   "source": [
    "So what if we want to add the owned status column using Series? We can use the method below. This will add a new column with the values from Series. Series must be the same length as the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Series\n",
    "s = pd.Series(['Canceled', 'Active', 'Canceled', 'Active', 'Active'])\n",
    "\n",
    "# Add the Series as a new column in the DataFrame\n",
    "passenger_df['status'] = s\n",
    "\n",
    "passenger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608c08b9",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked | discount | status |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.0 | C10 | S | 0.15 | Canceled |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.5 | E25 | C | 0.15 | Active |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.0 | G12 | Q | 0.15 | Canceled |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.0 | A5 | S | 0.15 | Active |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.0 | B15 | S | 0.15 | Active |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42035590",
   "metadata": {},
   "source": [
    "# 3. Adding a column with a calculated value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020aabe8",
   "metadata": {},
   "source": [
    "We can add new columns that are calculated from existing columns. After previously we added discount for all passengers, in this case we want to add a column to see the total fare after the discount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7da2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_df['totalFare'] = passenger_df['fare'] - (passenger_df['fare'] * passenger_df['discount'])\n",
    "\n",
    "passenger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4bea54",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.0 | C10 | S | 0.15 | Canceled | 42.500 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.5 | E25 | C | 0.15 | Active | 25.925 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.0 | G12 | Q | 0.15 | Canceled | 8.500 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.0 | A5 | S | 0.15 | Active | 85.000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.0 | B15 | S | 0.15 | Active | 17.000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1c6e38",
   "metadata": {},
   "source": [
    "# Updating Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c06eaf",
   "metadata": {},
   "source": [
    "Updating a column in a DataFrame is similar to adding a new column. We assign the new values to the column we want to update. The new values could be a scalar, a Series, or a calculated value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cbfc6c",
   "metadata": {},
   "source": [
    "# 1. Updating a column with a scalar value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f2c29",
   "metadata": {},
   "source": [
    "This will update the specified column with the supplied scalar value for all rows. For example, we want to change the amount of the discount given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b7f244",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_df['discount'] = 0.25\n",
    "\n",
    "passenger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3bb71",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.0 | C10 | S | 0.25 | Canceled | 42.500 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.5 | E25 | C | 0.25 | Active | 25.925 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.0 | G12 | Q | 0.25 | Canceled | 8.500 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.0 | A5 | S | 0.25 | Active | 85.000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.0 | B15 | S | 0.25 | Active | 17.000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50dcee7b",
   "metadata": {},
   "source": [
    "# 2. Updating a column with a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df88caa",
   "metadata": {},
   "source": [
    "This will update the specified column with the value from Series. Series must be the same length as the DataFrame. In this case, it turns out that we know that the status of some passengers is wrong and we want to replace it using the data series we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b76aa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_series = pd.Series(['Active', 'Active', 'Active', 'Active', 'Canceled', 'Active', 'Active', 'Canceled','Active', 'Active', 'Canceled', 'Active', 'Active', 'Canceled','Active', 'Canceled', 'Active', 'Active', 'Canceled','Active',])\n",
    "\n",
    "passenger_df['status'] = new_series\n",
    "\n",
    "passenger_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84909f9c",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.00 | C10 | S | 0.25 | Active | 42.5000 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.50 | E25 | C | 0.25 | Active | 25.9250 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q | 0.25 | Active | 8.5000 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S | 0.25 | Active | 85.0000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S | 0.25 | Canceled | 17.0000 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 13.3875 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 68.4250 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 29.9625 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 7.2250 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 76.5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d82421",
   "metadata": {},
   "source": [
    "# 3. Updating a column with a calculated value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99628e9b",
   "metadata": {},
   "source": [
    "We can update columns with values calculated from other columns. For example, after we change the amount of discount given, we also need to change the calculation format and amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_df['totalFare'] = passenger_df['fare'] - (passenger_df['fare'] * passenger_df['discount']) \n",
    "\n",
    "passenger_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555fc35",
   "metadata": {},
   "source": [
    "|  | passengerId | class | sex | age | ticket | fare | cabin | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.00 | C10 | S | 0.25 | Active | 37.5000 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.50 | E25 | C | 0.25 | Active | 22.8750 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q | 0.25 | Active | 7.5000 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S | 0.25 | Active | 75.0000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S | 0.25 | Canceled | 15.0000 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecf0af8",
   "metadata": {},
   "source": [
    "# Updating Column Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d412f76f",
   "metadata": {},
   "source": [
    "At times, the naming of columns or features may lack consistency, possibly due to variations in letter case, among other factors. Maintaining a uniform naming convention enhances our efficiency when working with these features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0121e8b1",
   "metadata": {},
   "source": [
    "Let’s explore how we can modify or update the names of columns or features in our dataset. For example, we think that the column name sex is taboo or inappropriate, and we want to replace it with gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0486be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#update the column name\n",
    "passenger_df = passenger_df.rename(columns = {'sex':'gender'})\n",
    "\n",
    "passenger_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb4a598",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticket | fare | cabin | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.0 | C10 | S | 0.25 | Active | 37.500 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.5 | E25 | C | 0.25 | Active | 22.875 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.0 | G12 | Q | 0.25 | Active | 7.500 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.0 | A5 | S | 0.25 | Active | 75.000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.0 | B15 | S | 0.25 | Canceled | 15.000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9519630",
   "metadata": {},
   "source": [
    "You can even update multiple column names at a single time. For that, you have to add other column names separated by a comma under the curl braces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911a65a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multiple column update\n",
    "passenger_df = passenger_df.rename(columns = {'ticket':'ticketNumber','cabin':'cabinNumber'})\n",
    "\n",
    "passenger_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce68f8d3",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.00 | C10 | S | 0.25 | Active | 37.5000 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.50 | E25 | C | 0.25 | Active | 22.8750 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q | 0.25 | Active | 7.5000 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S | 0.25 | Active | 75.0000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S | 0.25 | Canceled | 15.0000 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.25 | Active | 9.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.25 | Active | 5.6250 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.25 | Active | 10.1250 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ba8dd4",
   "metadata": {},
   "source": [
    "# Adding, Updating and Deleting Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a9567",
   "metadata": {},
   "source": [
    "# Adding Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89794ee6",
   "metadata": {},
   "source": [
    "There are 2 ways to add rows into Pandas DataFrame object: 1. Use the DataFrame object’s loc attribute. 2. Use the DataFrame object’s concat method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb25168",
   "metadata": {},
   "source": [
    "# 1. Adding Rows Using loc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be9fe9b4",
   "metadata": {},
   "source": [
    "What if we want to add the latest passenger data? One of them we can use loc as below. When adding a new row using loc, we can specify the index label of the new row. If this label doesn’t already exist, loc will add a new row with this label to the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b4edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_row = {'passengerId': 21,\n",
    "           'class':'Third',\n",
    "           'gender':'Male',\n",
    "           'age':30,\n",
    "           'ticketNumber': 'F73925',\n",
    "           'fare':35,\n",
    "           'cabinNumber':'A55',\n",
    "           'embarked': 'C',\n",
    "           'discount': 0.25,\n",
    "           'status': 'Active',\n",
    "           'totalFare': 37.500}\n",
    "\n",
    "passenger_df.loc[len(passenger_df)] = new_row\n",
    "\n",
    "passenger_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf42ed72",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.00 | C10 | S | 0.25 | Active | 37.5000 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.50 | E25 | C | 0.25 | Active | 22.8750 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q | 0.25 | Active | 7.5000 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S | 0.25 | Active | 75.0000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S | 0.25 | Canceled | 15.0000 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.25 | Active | 9.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.25 | Active | 5.6250 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.25 | Active | 10.1250 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |\n",
    "| 20 | 21 | Third | Male | 30 | F73925 | 35.00 | A55 | C | 0.25 | Active | 37.5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a6911",
   "metadata": {},
   "source": [
    "# 2. Adding Rows Using concat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e369b5",
   "metadata": {},
   "source": [
    "Or if we have another DataFrame and want to add it to our existing DataFrame. We can use the concat function. The concat function is used to concat another DataFrame row to the end of the given DataFrame, returning a new DataFrame object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df186082",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_rows = {'passengerId': [22, 23],\n",
    "            'class':['First','Third'],\n",
    "            'gender':['Male','Female'],\n",
    "            'age':[30,30],\n",
    "            'ticketNumber': ['G76201', 'H43599'],\n",
    "            'fare':[50,35],\n",
    "            'cabinNumber':['B5', 'B6'],\n",
    "            'embarked': ['C', 'S'],\n",
    "            'discount':[0.25, 0.25],\n",
    "            'status': ['Active','Active'],\n",
    "            'totalFare': [37.500, 37.500]}\n",
    "\n",
    "new_passenger_df = pd.DataFrame(data = new_rows)\n",
    "\n",
    "passenger_df = pd.concat([passenger_df, new_passenger_df], ignore_index=True)\n",
    "\n",
    "passenger_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716e3dac",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1 | First | Male | 32 | A12345 | 50.00 | C10 | S | 0.25 | Active | 37.5000 |\n",
    "| 1 | 2 | Second | Female | 25 | B67890 | 30.50 | E25 | C | 0.25 | Active | 22.8750 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q | 0.25 | Active | 7.5000 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S | 0.25 | Active | 75.0000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S | 0.25 | Canceled | 15.0000 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.25 | Active | 9.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.25 | Active | 5.6250 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.25 | Active | 10.1250 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |\n",
    "| 20 | 21 | Third | Male | 30 | F73925 | 35.00 | A55 | C | 0.25 | Active | 37.5000 |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.25 | Active | 37.5000 |\n",
    "| 22 | 23 | Third | Female | 30 | H43599 | 35.00 | B6 | S | 0.25 | Active | 37.5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040cdea",
   "metadata": {},
   "source": [
    "# Updating Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b85e8bca",
   "metadata": {},
   "source": [
    "You can update the values in a row using the loc indexer. The loc indexer is used to access a group of rows and columns by label(s) or a boolean array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df18df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a row\n",
    "passenger_df.loc[0, ['passengerId', 'cabinNumber']] = [24, 'C1']\n",
    "passenger_df.loc[1] = {'passengerId': 2, 'class':'Second', 'gender':'Female', 'age':'18', 'ticketNumber': 'B67890', 'fare':40, 'cabinNumber':'A1','embarked': 'Q', 'discount':0.25, 'status': 'Active', 'totalFare': 22.875}\n",
    "\n",
    "passenger_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21490257",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 24 | First | Male | 32 | A12345 | 50.00 | C1 | S | 0.25 | Active | 37.5000 |\n",
    "| 1 | 2 | Second | Female | 18 | B67890 | 40.00 | A1 | Q | 0.25 | Active | 22.8750 |\n",
    "| 2 | 3 | Third | Male | 18 | C24680 | 10.00 | G12 | Q | 0.25 | Active | 7.5000 |\n",
    "| 3 | 4 | First | Female | 40 | D13579 | 100.00 | A5 | S | 0.25 | Active | 75.0000 |\n",
    "| 4 | 5 | Second | Male | 35 | E97531 | 20.00 | B15 | S | 0.25 | Canceled | 15.0000 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.25 | Active | 9.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.25 | Active | 5.6250 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.25 | Active | 10.1250 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |\n",
    "| 20 | 21 | Third | Male | 30 | F73925 | 35.00 | A55 | C | 0.25 | Active | 37.5000 |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.25 | Active | 37.5000 |\n",
    "| 22 | 23 | Third | Female | 30 | H43599 | 35.00 | B6 | S | 0.25 | Active | 37.5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052ada0f",
   "metadata": {},
   "source": [
    "# Deleting/Dropping Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d54e88d",
   "metadata": {},
   "source": [
    "You can delete rows from your DataFrame using the drop() function. This function removes the row or column(s) you specify from your DataFrame. The axis parameter indicates whether you want to drop labels from the index (axis=0 or axis='index') or columns (axis=1 or axis='columns')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d5492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting single row\n",
    "passenger_df = passenger_df.drop(2, axis=0)\n",
    "\n",
    "# deleting multiple rows\n",
    "passenger_df = passenger_df.drop([3, 4], axis=0)\n",
    "\n",
    "passenger_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5abf232",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 24 | First | Male | 32 | A12345 | 50.00 | C1 | S | 0.25 | Active | 37.5000 |\n",
    "| 1 | 2 | Second | Female | 18 | B67890 | 40.00 | A1 | Q | 0.25 | Active | 22.8750 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.25 | Active | 9.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.25 | Active | 5.6250 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.25 | Active | 10.1250 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |\n",
    "| 20 | 21 | Third | Male | 30 | F73925 | 35.00 | A55 | C | 0.25 | Active | 37.5000 |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.25 | Active | 37.5000 |\n",
    "| 22 | 23 | Third | Female | 30 | H43599 | 35.00 | B6 | S | 0.25 | Active | 37.5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab494608",
   "metadata": {},
   "source": [
    "# Sorting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7a955b",
   "metadata": {},
   "source": [
    "Sorting data in a Pandas DataFrame is a common operation that can be done using the sort_values() function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405fbf33",
   "metadata": {},
   "source": [
    "We can sort by one or more columns. For example, here we want to see the ticket prices paid by passengers by sorting them. Here’s how you do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91714390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'fare' in ascending order\n",
    "df_asc = passenger_df.sort_values('fare')\n",
    "\n",
    "df_asc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d08571",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.25 | Active | 5.6250 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.25 | Active | 9.3750 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.25 | Active | 10.1250 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 22 | 23 | Third | Female | 30 | H43599 | 35.00 | B6 | S | 0.25 | Active | 37.5000 |\n",
    "| 20 | 21 | Third | Male | 30 | F73925 | 35.00 | A55 | C | 0.25 | Active | 37.5000 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4721190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'fare' in descending order\n",
    "df_desc = passenger_df.sort_values('fare', ascending=False)\n",
    "\n",
    "df_desc.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a68511a",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 0 | 24 | First | Male | 32 | A12345 | 50.00 | C1 | S | 0.25 | Active | 37.5000 |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.25 | Active | 37.5000 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |\n",
    "| 1 | 2 | Second | Female | 18 | B67890 | 40.00 | A1 | Q | 0.25 | Active | 22.8750 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21196bc9",
   "metadata": {},
   "source": [
    "We can also sort by multiple columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48abd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'class' and then 'cabinNumber', both in ascending order\n",
    "df_sorted = passenger_df.sort_values(['class', 'cabinNumber'])\n",
    "\n",
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e22fa60",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.25 | Active | 37.5000 |\n",
    "| 0 | 24 | First | Male | 32 | A12345 | 50.00 | C1 | S | 0.25 | Active | 37.5000 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 1 | 2 | Second | Female | 18 | B67890 | 40.00 | A1 | Q | 0.25 | Active | 22.8750 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e55da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by 'class' in ascending order, then 'cabinNumber' in descending order\n",
    "df_sorted = passenger_df.sort_values(['class', 'cabinNumber'], ascending=[True, False])\n",
    "\n",
    "df_sorted.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d41227b",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 0 | 24 | First | Male | 32 | A12345 | 50.00 | C1 | S | 0.25 | Active | 37.5000 |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.25 | Active | 37.5000 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e9fb4e",
   "metadata": {},
   "source": [
    "After sorting, if you want to reset the index, we can use the reset_index() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0de538",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sorted = df_sorted.reset_index(drop=True)\n",
    "\n",
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012fc172",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.25 | Canceled | 52.8750 |\n",
    "| 1 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.25 | Active | 67.5000 |\n",
    "| 2 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.25 | Canceled | 71.2500 |\n",
    "| 3 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.25 | Active | 60.3750 |\n",
    "| 4 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.25 | Active | 56.6250 |\n",
    "| 5 | 24 | First | Male | 32 | A12345 | 50.00 | C1 | S | 0.25 | Active | 37.5000 |\n",
    "| 6 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.25 | Active | 37.5000 |\n",
    "| 7 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.25 | Active | 33.9375 |\n",
    "| 8 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.25 | Active | 16.5000 |\n",
    "| 9 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.25 | Canceled | 26.4375 |\n",
    "| 10 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.25 | Canceled | 30.1875 |\n",
    "| 11 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.25 | Canceled | 18.7500 |\n",
    "| 12 | 2 | Second | Female | 18 | B67890 | 40.00 | A1 | Q | 0.25 | Active | 22.8750 |\n",
    "| 13 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.25 | Active | 10.1250 |\n",
    "| 14 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.25 | Active | 6.3750 |\n",
    "| 15 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.25 | Active | 5.6250 |\n",
    "| 16 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.25 | Active | 11.8125 |\n",
    "| 17 | 23 | Third | Female | 30 | H43599 | 35.00 | B6 | S | 0.25 | Active | 37.5000 |\n",
    "| 18 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.25 | Active | 9.3750 |\n",
    "| 19 | 21 | Third | Male | 30 | F73925 | 35.00 | A55 | C | 0.25 | Active | 37.5000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6bcb88",
   "metadata": {},
   "source": [
    "# Operations on DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc1dcbe",
   "metadata": {},
   "source": [
    "# Arithmetic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c02fe3",
   "metadata": {},
   "source": [
    "Arithmetic operations can be performed on the numeric columns in DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0376aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_df['discount'] = passenger_df['discount'] + 0.1\n",
    "passenger_df['totalFare'] = passenger_df['fare'] - (passenger_df['fare'] * passenger_df['discount']) \n",
    "passenger_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8a1a4e",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 24 | First | Male | 32 | A12345 | 50.00 | C1 | S | 0.35 | Active | 32.5000 |\n",
    "| 1 | 2 | Second | Female | 18 | B67890 | 40.00 | A1 | Q | 0.35 | Active | 26.0000 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 15.75 | C30 | Q | 0.35 | Active | 10.2375 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 80.50 | D8 | C | 0.35 | Active | 52.3250 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 35.25 | E12 | S | 0.35 | Canceled | 22.9125 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 8.50 | F20 | S | 0.35 | Active | 5.5250 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 90.00 | G5 | C | 0.35 | Active | 58.5000 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 25.00 | A20 | S | 0.35 | Canceled | 16.2500 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 12.50 | B30 | Q | 0.35 | Active | 8.1250 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 75.50 | C8 | S | 0.35 | Active | 49.0750 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 40.25 | D12 | C | 0.35 | Canceled | 26.1625 |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 7.50 | E20 | S | 0.35 | Active | 4.8750 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 95.00 | F5 | S | 0.35 | Canceled | 61.7500 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 22.00 | G20 | S | 0.35 | Active | 14.3000 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 13.50 | H30 | Q | 0.35 | Active | 8.7750 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 70.50 | I8 | C | 0.35 | Canceled | 45.8250 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 45.25 | J12 | S | 0.35 | Active | 29.4125 |\n",
    "| 20 | 21 | Third | Male | 30 | F73925 | 35.00 | A55 | C | 0.35 | Active | 22.7500 |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 50.00 | B5 | C | 0.35 | Active | 32.5000 |\n",
    "| 22 | 23 | Third | Female | 30 | H43599 | 35.00 | B6 | S | 0.35 | Active | 22.7500 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbd4649",
   "metadata": {},
   "source": [
    "Arithmetic operations are essential in feature engineering where you create new features from existing ones to provide more information to your machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf2c611",
   "metadata": {},
   "source": [
    "# Aggregation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa55c384",
   "metadata": {},
   "source": [
    "Aggregation functions in DataFrames are used to perform mathematical computations on groups of data. These functions provide a way to perform operations on groups of values, summarizing the information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70816b",
   "metadata": {},
   "source": [
    "Common aggregation functions include:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc600171",
   "metadata": {},
   "source": [
    "count(): Returns the number of non-null values in each DataFrame column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1be29b",
   "metadata": {},
   "source": [
    "sum(): Returns the sum of the values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b8ab7c",
   "metadata": {},
   "source": [
    "mean(): Returns the mean of the values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70804ef",
   "metadata": {},
   "source": [
    "median(): Returns the median of the values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ee517a",
   "metadata": {},
   "source": [
    "min(): Returns the minimum of the values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd7139a",
   "metadata": {},
   "source": [
    "max(): Returns the maximum of the values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b81585",
   "metadata": {},
   "source": [
    "std(): Returns the standard deviation of the values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfb541",
   "metadata": {},
   "source": [
    "var(): Returns the variance of values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07888fc2",
   "metadata": {},
   "source": [
    "first(): Returns the first of the values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74d49a9",
   "metadata": {},
   "source": [
    "last(): Returns the last of the values for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad509683",
   "metadata": {},
   "outputs": [],
   "source": [
    "passenger_df['age'] = passenger_df['age'].astype(int)\n",
    "\n",
    "# get the mean of 'Age'\n",
    "mean_age = passenger_df['age'].mean()\n",
    "print('Mean age: ',mean_age)\n",
    "\n",
    "# get the standard deviation of 'Age'\n",
    "std_age = passenger_df['age'].std()\n",
    "print('std age: ',std_age)\n",
    "\n",
    "# get the summary statistics of the dataframe\n",
    "summary = passenger_df.describe()\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0911ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "Mean age:  31.95\n",
    "std age:  11.966950101711047"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24af9d",
   "metadata": {},
   "source": [
    "|  | passengerId | age | fare | discount | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- |\n",
    "| count | 20.000000 | 20.00000 | 20.000000 | 2.000000e+01 | 20.000000 |\n",
    "| mean | 14.350000 | 31.95000 | 42.350000 | 3.500000e-01 | 27.527500 |\n",
    "| std | 6.200806 | 11.96695 | 27.327979 | 1.139065e-16 | 17.763186 |\n",
    "| min | 2.000000 | 18.00000 | 7.500000 | 3.500000e-01 | 4.875000 |\n",
    "| 25% | 9.750000 | 23.50000 | 20.437500 | 3.500000e-01 | 13.284375 |\n",
    "| 50% | 14.500000 | 30.00000 | 37.625000 | 3.500000e-01 | 24.456250 |\n",
    "| 75% | 19.250000 | 34.25000 | 55.125000 | 3.500000e-01 | 35.831250 |\n",
    "| max | 24.000000 | 60.00000 | 95.000000 | 3.500000e-01 | 61.750000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f615b81",
   "metadata": {},
   "source": [
    "This is often the first step in any data analysis process to understand the distribution and central tendencies of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12f9647",
   "metadata": {},
   "source": [
    "# Applying Functions in DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7fbfe0",
   "metadata": {},
   "source": [
    "Applying functions is a way to perform operations on a DataFrame or a series (column of a DataFrame). This is done using the apply() function in Pandas. The apply() function takes a function as an argument and applies this function to an entire DataFrame or series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60128e3e",
   "metadata": {},
   "source": [
    "# DataFrame.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fba7ff",
   "metadata": {},
   "source": [
    "When used on a DataFrame, apply() applies the function to each column of the DataFrame (default behavior), returning a series where each element is the result of applying the function to a column. If you want to apply the function to each row, you can set the axis parameter to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb140c5",
   "metadata": {},
   "source": [
    "For example, here we want to make a recent fare adjustment by increasing the fare by 5 dollars. Then, we also need to make adjustments to the totalFare. We can do it in the following way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124d18b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add passenger 'fare' by adding 5 to the 'fare'\n",
    "passenger_df['fare'] = passenger_df['fare'].apply(lambda x: x + 5)\n",
    "\n",
    "# Define the function to be applied\n",
    "def calculate_total_fare(row):\n",
    "    return row['fare'] - (row['fare'] * row['discount'])\n",
    "\n",
    "# Use the function on every row in the dataframe\n",
    "passenger_df['totalFare'] = passenger_df.apply(calculate_total_fare, axis=1)\n",
    "\n",
    "passenger_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6d4c07",
   "metadata": {},
   "source": [
    "|  | passengerId | class | gender | age | ticketNumber | fare | cabinNumber | embarked | discount | status | totalFare |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 24 | First | Male | 32 | A12345 | 55.00 | C1 | S | 0.35 | Active | 35.7500 |\n",
    "| 1 | 2 | Second | Female | 18 | B67890 | 45.00 | A1 | Q | 0.35 | Active | 29.2500 |\n",
    "| 5 | 6 | Third | Female | 28 | F86420 | 20.75 | C30 | Q | 0.35 | Active | 13.4875 |\n",
    "| 6 | 7 | First | Male | 50 | G75319 | 85.50 | D8 | C | 0.35 | Active | 55.5750 |\n",
    "| 7 | 8 | Second | Female | 22 | H64208 | 40.25 | E12 | S | 0.35 | Canceled | 26.1625 |\n",
    "| 8 | 9 | Third | Male | 19 | I35790 | 13.50 | F20 | S | 0.35 | Active | 8.7750 |\n",
    "| 9 | 10 | First | Female | 45 | J86420 | 95.00 | G5 | C | 0.35 | Active | 61.7500 |\n",
    "| 10 | 11 | Second | Male | 30 | K97531 | 30.00 | A20 | S | 0.35 | Canceled | 19.5000 |\n",
    "| 11 | 12 | Third | Female | 21 | L24680 | 17.50 | B30 | Q | 0.35 | Active | 11.3750 |\n",
    "| 12 | 13 | First | Male | 55 | M75319 | 80.50 | C8 | S | 0.35 | Active | 52.3250 |\n",
    "| 13 | 14 | Second | Female | 28 | N64208 | 45.25 | D12 | C | 0.35 | Canceled | 29.4125 |\n",
    "| 14 | 15 | Third | Male | 20 | O35790 | 12.50 | E20 | S | 0.35 | Active | 8.1250 |\n",
    "| 15 | 16 | First | Female | 38 | P86420 | 100.00 | F5 | S | 0.35 | Canceled | 65.0000 |\n",
    "| 16 | 17 | Second | Male | 33 | Q97531 | 27.00 | G20 | S | 0.35 | Active | 17.5500 |\n",
    "| 17 | 18 | Third | Female | 26 | R24680 | 18.50 | H30 | Q | 0.35 | Active | 12.0250 |\n",
    "| 18 | 19 | First | Male | 60 | S75319 | 75.50 | I8 | C | 0.35 | Canceled | 49.0750 |\n",
    "| 19 | 20 | Second | Female | 24 | T64208 | 50.25 | J12 | S | 0.35 | Active | 32.6625 |\n",
    "| 20 | 21 | Third | Male | 30 | F73925 | 40.00 | A55 | C | 0.35 | Active | 26.0000 |\n",
    "| 21 | 22 | First | Male | 30 | G76201 | 55.00 | B5 | C | 0.35 | Active | 35.7500 |\n",
    "| 22 | 23 | Third | Female | 30 | H43599 | 40.00 | B6 | S | 0.35 | Active | 26.0000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ecdcd9",
   "metadata": {},
   "source": [
    "# Introduction to Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe87ff04",
   "metadata": {},
   "source": [
    "# What is Data Cleaning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326995de",
   "metadata": {},
   "source": [
    "Data cleaning, also known as data cleansing or data scrubbing, is the process of identifying and correcting or removing errors, inaccuracies, and inconsistencies in datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03e2225",
   "metadata": {},
   "source": [
    "This process is crucial in improving the quality and reliability of data, which is particularly important in data analysis and machine learning models where the output quality is directly dependent on the input quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfaf6d1",
   "metadata": {},
   "source": [
    "In the context of the Python programming language, the Pandas library is often used for data cleaning. Pandas is a powerful data manipulation tool that provides functions for reading, writing, and modifying datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01f64ea",
   "metadata": {},
   "source": [
    "# Why is Data Cleaning Important?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9a7da2",
   "metadata": {},
   "source": [
    "Data cleaning is a critical step in the data analysis process for several reasons:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d68024",
   "metadata": {},
   "source": [
    "Improving Data Quality: Raw data often contains errors, outliers, or inconsistencies that can distort analysis results. Data cleaning helps to ensure that the data used for analysis is accurate and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f62f1d",
   "metadata": {},
   "source": [
    "Enhancing Data Accuracy: Inaccurate data can lead to inaccurate conclusions. By cleaning data, you can ensure that your analyses and models are based on the most accurate information possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f464dd01",
   "metadata": {},
   "source": [
    "Boosting Efficiency: Clean data is easier to work with and can make data analysis processes more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d2aeef",
   "metadata": {},
   "source": [
    "Better Decision Making: Clean data leads to more reliable analysis, which in turn leads to better decision-making. This is particularly important in fields like business or research where decisions need to be data-driven."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d24ef5b",
   "metadata": {},
   "source": [
    "Ensuring Compliance: In some industries, maintaining clean data is a regulatory requirement. Data cleaning can help ensure compliance with these regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466718b1",
   "metadata": {},
   "source": [
    "# Data Cleaning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ba5c6f",
   "metadata": {},
   "source": [
    " (Sumber: knowledgehut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120cf2cd",
   "metadata": {},
   "source": [
    "![Image](https://storage.googleapis.com/rg-ai-bootcamp/toolkits/data-cleaning-in-data-science-min.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4721f5e2",
   "metadata": {},
   "source": [
    "# Handling Missing Data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e6475",
   "metadata": {},
   "source": [
    "Missing data is a common issue in data analysis. It refers to the absence of data in a column of a dataset. In Python’s Pandas library, missing data is represented by NaN (Not a Number) or None."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a0c3caf",
   "metadata": {},
   "source": [
    "# Detecting Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cdd8c0",
   "metadata": {},
   "source": [
    "Pandas provides the isnull() and notnull() functions to detect missing data. These functions return a Boolean mask indicating whether each element in the DataFrame is missing or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e53d6d",
   "metadata": {},
   "source": [
    "Let’s take a look at the customer data we used earlier. We will find out if there is missing data in the customer data that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf2263d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "airbnb_df = pd.read_csv('https://storage.googleapis.com/rg-ai-bootcamp/pandas/airbnb-data.csv')\n",
    "airbnb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c42c9d",
   "metadata": {},
   "source": [
    "|  | id | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count | license |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1001254.0 | Clean & quiet apt home by the park | 8.001449e+10 | unconfirmed | Madaline | Brooklyn | Kensington | United States | US | False | Private room | 2020.0 | $966 | $193 | 10.0 | 9.0 | 4.0 | 6.0 | NaN |\n",
    "| 1 | 1002102.0 | Skylit Midtown Castle | 5.233517e+10 | verified | Jenna | Manhattan | Midtown | United States | US | False | Entire home/apt | 2007.0 | $142 | $28 | 30.0 | 45.0 | 4.0 | 2.0 | NaN |\n",
    "| 2 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN |\n",
    "| 3 | 1002403.0 | THE VILLAGE OF HARLEM....NEW YORK ! | 7.882924e+10 | NaN | Elise | Manhattan | Harlem | United States | US | True | Private room | 2005.0 | $620 | $124 | 3.0 | 0.0 | 5.0 | 1.0 | NaN |\n",
    "| 4 | 1002755.0 | NaN | 8.509833e+10 | unconfirmed | Garry | Brooklyn | Clinton Hill | United States | US | True | Entire home/apt | 2005.0 | $368 | $74 | 30.0 | 270.0 | 4.0 | 1.0 | NaN |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 3631 | 2998453.0 | Upper West Side elegance. Riverside | 3.204065e+10 | unconfirmed | Poppi | Manhattan | Upper West Side | United States | US | False | Entire home/apt | 2008.0 | $620 | $124 | 1.0 | 5.0 | 1.0 | 2.0 | NaN |\n",
    "| 3632 | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN | NaN |\n",
    "| 3633 | 2999005.0 | BIG, BRIGHT, STYLISH + CONVENIENT | 4.074627e+10 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3.0 | 90.0 | 2.0 | 1.0 | NaN |\n",
    "| 3634 | 2999005.0 | BIG, BRIGHT, STYLISH + CONVENIENT | 4.074627e+10 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3.0 | 90.0 | 2.0 | 1.0 | NaN |\n",
    "| 3635 | 2999557.0 | Exclusive Upper East Side Studio | 2.446375e+10 | verified | Ellen | Manhattan | Upper East Side | United States | US | True | Entire home/apt | 2022.0 | $655 | $131 | 1.0 | 0.0 | 5.0 | 1.0 | NaN |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d84c7c4",
   "metadata": {},
   "source": [
    "3636 rows × 19 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0ff8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect missing values\n",
    "airbnb_df.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dabab7",
   "metadata": {},
   "source": [
    "|  | id | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count | license |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |\n",
    "| 1 | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |\n",
    "| 2 | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True |\n",
    "| 3 | False | False | False | True | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |\n",
    "| 4 | False | True | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 3631 | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |\n",
    "| 3632 | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True | True |\n",
    "| 3633 | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |\n",
    "| 3634 | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |\n",
    "| 3635 | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | False | True |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a675212",
   "metadata": {},
   "source": [
    "3636 rows × 19 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3409a43",
   "metadata": {},
   "source": [
    "This will print a DataFrame with the same size as the original, but with True in place where the original DataFrame had NaN or None, and False elsewhere. as can be seen that the row with index 2 has a value of true in each column, which means that there is missing data in that row."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc069527",
   "metadata": {},
   "source": [
    "To be clear, if we want to know the amount and percentage of missing data, we can do it in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea1298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of missing data\n",
    "total = airbnb_df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "# Calculates the percentage of missing data\n",
    "persentase = (airbnb_df.isnull().sum()/airbnb_df.isnull().count()*100).sort_values(ascending=False)\n",
    "\n",
    "# Creates a new DataFrame to display the results\n",
    "missing_data = pd.concat([total, persentase], axis=1, keys=['Total', 'Persentase'])\n",
    "\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117fb29",
   "metadata": {},
   "source": [
    "|  | Total | Persentase |\n",
    "| --- | --- | --- |\n",
    "| license | 3636 | 100.000000 |\n",
    "| construction_year | 138 | 3.795380 |\n",
    "| review_rate_number | 96 | 2.640264 |\n",
    "| minimum_nights | 87 | 2.392739 |\n",
    "| country_code | 82 | 2.255226 |\n",
    "| instant_bookable | 82 | 2.255226 |\n",
    "| host_identity_verified | 78 | 2.145215 |\n",
    "| name | 60 | 1.650165 |\n",
    "| country | 53 | 1.457646 |\n",
    "| neighbourhood_group | 31 | 0.852585 |\n",
    "| host_name | 23 | 0.632563 |\n",
    "| neighbourhood | 19 | 0.522552 |\n",
    "| service_fee | 18 | 0.495050 |\n",
    "| calculated_host_listings_count | 18 | 0.495050 |\n",
    "| price | 14 | 0.385039 |\n",
    "| number_of_reviews | 10 | 0.275028 |\n",
    "| room_type | 3 | 0.082508 |\n",
    "| host_id | 3 | 0.082508 |\n",
    "| id | 3 | 0.082508 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c9dd16",
   "metadata": {},
   "source": [
    "# Dropping Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc830ffa",
   "metadata": {},
   "source": [
    "Pandas provides the dropna() function to remove missing data. By default, dropna() removes any row containing at least one missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c13a18",
   "metadata": {},
   "source": [
    "However, dropna() is more flexible than this. It provides several parameters that allow you to control how missing values are dropped:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee15ec4",
   "metadata": {},
   "source": [
    "Axis: By default, dropna() drops rows (axis=0). But you can also make it drop columns by setting axis=1. py     # Drop columns with missing values     df_dropped = df.dropna(axis=1) This will drop any column that contains at least one missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897b284",
   "metadata": {},
   "source": [
    "How: By default, dropna() drops a row or column if it contains any missing values (how='any'). But you can also make it drop only rows or columns where all values are missing by setting how='all'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2997c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all values are missing\n",
    "df_dropped = df.dropna(how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dae64c6",
   "metadata": {},
   "source": [
    "This will drop any row where all values are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c724f",
   "metadata": {},
   "source": [
    "Subset: You can specify a subset of columns to consider when dropping rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where 'house_rules' is missing\n",
    "df_dropped = df.dropna(subset=['house_rules'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a8d3f4",
   "metadata": {},
   "source": [
    "This will drop any row where ‘house_rules’ is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbcb8ff",
   "metadata": {},
   "source": [
    "Inplace: By default, dropna() returns a new DataFrame and leaves the original unchanged. If you want to modify the original DataFrame, you can set inplace=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82bb7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values in the original DataFrame\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ed4f52",
   "metadata": {},
   "source": [
    "This will drop rows with missing values directly in the original DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe5d9d1",
   "metadata": {},
   "source": [
    "As seen earlier the license column and some rows have no data at all, we will try to remove them using dropna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c23e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the column 'license' which has no data at all\n",
    "airbnb_df = airbnb_df.drop(['license'], axis=1)\n",
    "\n",
    "# Drop any line where 'id', 'name', 'host_id' and 'host_name' are missing\n",
    "airbnb_df = airbnb_df.dropna(subset=['id', 'name', 'host_id', 'host_name'])\n",
    "\n",
    "# Drop rows where all values are missing\n",
    "airbnb_df = airbnb_df.dropna(how='all')\n",
    "\n",
    "airbnb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facca6ef",
   "metadata": {},
   "source": [
    "|  | id | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1001254.0 | Clean & quiet apt home by the park | 8.001449e+10 | unconfirmed | Madaline | Brooklyn | Kensington | United States | US | False | Private room | 2020.0 | $966 | $193 | 10.0 | 9.0 | 4.0 | 6.0 |\n",
    "| 1 | 1002102.0 | Skylit Midtown Castle | 5.233517e+10 | verified | Jenna | Manhattan | Midtown | United States | US | False | Entire home/apt | 2007.0 | $142 | $28 | 30.0 | 45.0 | 4.0 | 2.0 |\n",
    "| 3 | 1002403.0 | THE VILLAGE OF HARLEM....NEW YORK ! | 7.882924e+10 | NaN | Elise | Manhattan | Harlem | United States | US | True | Private room | 2005.0 | $620 | $124 | 3.0 | 0.0 | 5.0 | 1.0 |\n",
    "| 5 | 1003689.0 | Entire Apt: Spacious Studio/Loft by central park | 9.203760e+10 | verified | Lyndon | Manhattan | East Harlem | United States | US | False | Entire home/apt | 2009.0 | $204 | $41 | 10.0 | 9.0 | 3.0 | 1.0 |\n",
    "| 6 | 1004098.0 | Large Cozy 1 BR Apartment In Midtown East | 4.549855e+10 | verified | Michelle | Manhattan | Murray Hill | United States | US | True | Entire home/apt | 2013.0 | $577 | $115 | 3.0 | 74.0 | 3.0 | 1.0 |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 3630 | 2997901.0 | Brooklyn NY, Comfy,Spacious Repose! | 5.626794e+10 | verified | Benjamin | Brooklyn | Bushwick | United States | US | False | Private room | 2007.0 | $767 | $153 | 3.0 | 40.0 | 2.0 | 1.0 |\n",
    "| 3631 | 2998453.0 | Upper West Side elegance. Riverside | 3.204065e+10 | unconfirmed | Poppi | Manhattan | Upper West Side | United States | US | False | Entire home/apt | 2008.0 | $620 | $124 | 1.0 | 5.0 | 1.0 | 2.0 |\n",
    "| 3633 | 2999005.0 | BIG, BRIGHT, STYLISH + CONVENIENT | 4.074627e+10 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3.0 | 90.0 | 2.0 | 1.0 |\n",
    "| 3634 | 2999005.0 | BIG, BRIGHT, STYLISH + CONVENIENT | 4.074627e+10 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3.0 | 90.0 | 2.0 | 1.0 |\n",
    "| 3635 | 2999557.0 | Exclusive Upper East Side Studio | 2.446375e+10 | verified | Ellen | Manhattan | Upper East Side | United States | US | True | Entire home/apt | 2022.0 | $655 | $131 | 1.0 | 0.0 | 5.0 | 1.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57b6f9",
   "metadata": {},
   "source": [
    "3562 rows × 18 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bced1fc5",
   "metadata": {},
   "source": [
    "This will remove the licence column and row where all values are missing as well as rows from the id, name, host_id and host_name columns which have missing data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfaeb43",
   "metadata": {},
   "source": [
    "# Filling Missing Data in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb50ce9",
   "metadata": {},
   "source": [
    "Instead of dropping missing values, we can also fill them with some value using the fillna() function. Pandas provides the fillna() function to fill missing values in a DataFrame. This function is highly flexible and allows you to fill missing values in a variety of ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab33c7a3",
   "metadata": {},
   "source": [
    "However, fillna() provides several parameters that allow you to control how missing values are filled:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b110d0e",
   "metadata": {},
   "source": [
    "Value: This is the value that will replace missing values. It can be a constant, or a dictionary, Series, or DataFrame that specifies different fill values for different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a06a6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with different values for different columns\n",
    "df_filled = df.fillna({'construction_year': 'unknown', 'minimum_nights': df['minimum_nights'].mean()})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353ccf35",
   "metadata": {},
   "source": [
    "Method: This specifies the method to use to fill missing values. Options include ‘forward fill’ (ffill or pad), which fills missing values with the previous value in the column, and ‘backward fill’ (bfill or backfill), which fills missing values with the next value in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bf0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill\n",
    "df_filled = df.fillna(method='ffill')\n",
    "\n",
    "# Backward fill\n",
    "df_filled = df.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8b4965",
   "metadata": {},
   "source": [
    "Axis: By default, fillna() fills missing values along the rows (axis=0). But you can also make it fill along the columns by setting axis=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d566a6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill along columns\n",
    "df_filled = df.fillna(method='ffill', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0dbcbe",
   "metadata": {},
   "source": [
    "Inplace: By default, fillna() returns a new DataFrame and leaves the original unchanged. If you want to modify the original DataFrame, you can set inplace=True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280ab470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in the original DataFrame\n",
    "df.fillna(\"Unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889df0f6",
   "metadata": {},
   "source": [
    "As seen earlier, some of the columns have missing values. Now we will try to fill in the missing values using fillna()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df = airbnb_df.fillna({\n",
    "'construction_year': 'unknown',\n",
    "'review_rate_number': airbnb_df['review_rate_number'].mean(),\n",
    "'minimum_nights': airbnb_df['minimum_nights'].mean(),\n",
    "'instant_bookable': 'unknown',\n",
    "'country_code': 'unknown',\n",
    "'host_identity_verified': 'unknown',\n",
    "'country': 'unknown',\n",
    "'neighbourhood_group': 'unknown',\n",
    "'neighbourhood': 'unknown',\n",
    "'service_fee': 'unknown',\n",
    "'calculated_host_listings_count': airbnb_df['calculated_host_listings_count'].mean(),\n",
    "'price': 'unknown',\n",
    "'number_of_reviews': airbnb_df['number_of_reviews'].mean(),\n",
    "})\n",
    "\n",
    "airbnb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9416d7",
   "metadata": {},
   "source": [
    "|  | id | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1001254.0 | Clean & quiet apt home by the park | 8.001449e+10 | unconfirmed | Madaline | Brooklyn | Kensington | United States | US | False | Private room | 2020.0 | $966 | $193 | 10.0 | 9.0 | 4.0 | 6.0 |\n",
    "| 1 | 1002102.0 | Skylit Midtown Castle | 5.233517e+10 | verified | Jenna | Manhattan | Midtown | United States | US | False | Entire home/apt | 2007.0 | $142 | $28 | 30.0 | 45.0 | 4.0 | 2.0 |\n",
    "| 3 | 1002403.0 | THE VILLAGE OF HARLEM....NEW YORK ! | 7.882924e+10 | unknown | Elise | Manhattan | Harlem | United States | US | True | Private room | 2005.0 | $620 | $124 | 3.0 | 0.0 | 5.0 | 1.0 |\n",
    "| 5 | 1003689.0 | Entire Apt: Spacious Studio/Loft by central park | 9.203760e+10 | verified | Lyndon | Manhattan | East Harlem | United States | US | False | Entire home/apt | 2009.0 | $204 | $41 | 10.0 | 9.0 | 3.0 | 1.0 |\n",
    "| 6 | 1004098.0 | Large Cozy 1 BR Apartment In Midtown East | 4.549855e+10 | verified | Michelle | Manhattan | Murray Hill | United States | US | True | Entire home/apt | 2013.0 | $577 | $115 | 3.0 | 74.0 | 3.0 | 1.0 |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 3630 | 2997901.0 | Brooklyn NY, Comfy,Spacious Repose! | 5.626794e+10 | verified | Benjamin | Brooklyn | Bushwick | United States | US | False | Private room | 2007.0 | $767 | $153 | 3.0 | 40.0 | 2.0 | 1.0 |\n",
    "| 3631 | 2998453.0 | Upper West Side elegance. Riverside | 3.204065e+10 | unconfirmed | Poppi | Manhattan | Upper West Side | United States | US | False | Entire home/apt | 2008.0 | $620 | $124 | 1.0 | 5.0 | 1.0 | 2.0 |\n",
    "| 3633 | 2999005.0 | BIG, BRIGHT, STYLISH + CONVENIENT | 4.074627e+10 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3.0 | 90.0 | 2.0 | 1.0 |\n",
    "| 3634 | 2999005.0 | BIG, BRIGHT, STYLISH + CONVENIENT | 4.074627e+10 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3.0 | 90.0 | 2.0 | 1.0 |\n",
    "| 3635 | 2999557.0 | Exclusive Upper East Side Studio | 2.446375e+10 | verified | Ellen | Manhattan | Upper East Side | United States | US | True | Entire home/apt | 2022.0 | $655 | $131 | 1.0 | 0.0 | 5.0 | 1.0 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c47457",
   "metadata": {},
   "source": [
    "3562 rows × 18 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6040a7b0",
   "metadata": {},
   "source": [
    "This will fill in missing values in the review_rate_number , minimum_nights, calculated_host_listings_count and number_of_reviews columns with the average and missing values in the other columns with unknown."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d6963d",
   "metadata": {},
   "source": [
    "# Data Type Conversion in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184482f0",
   "metadata": {},
   "source": [
    "Data type conversion, also known as type casting, is an important step in data cleaning. It involves converting data from one type to another. This is often necessary because the type of data that Pandas infers upon loading a dataset might not always be what you want."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54339e0b",
   "metadata": {},
   "source": [
    "# Converting Data Types in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883e437b",
   "metadata": {},
   "source": [
    "Data type conversion is a crucial step in data cleaning, especially when the data is imported from various sources which may categorize data in different types. Pandas provides the astype() function to convert data types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e07e88",
   "metadata": {},
   "source": [
    "As can be seen, the data in the id, host_id, minimum_nights, number_of_reviews,review_rate_number, and calculated_host_listings_count columns are of the float data type. We will convert the data into an integer using astype() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b904073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the column with the value `float` to `int`\n",
    "airbnb_df[['id', 'host_id', 'minimum_nights', 'number_of_reviews','review_rate_number','calculated_host_listings_count']] = airbnb_df[['id', 'host_id', 'minimum_nights', 'number_of_reviews','review_rate_number','calculated_host_listings_count']].astype(int)\n",
    "\n",
    "airbnb_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c31ff68",
   "metadata": {},
   "source": [
    "|  | id | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 0 | 1001254 | Clean & quiet apt home by the park | 80014485718 | unconfirmed | Madaline | Brooklyn | Kensington | United States | US | False | Private room | 2020.0 | $966 | $193 | 10 | 9 | 4 | 6 |\n",
    "| 1 | 1002102 | Skylit Midtown Castle | 52335172823 | verified | Jenna | Manhattan | Midtown | United States | US | False | Entire home/apt | 2007.0 | $142 | $28 | 30 | 45 | 4 | 2 |\n",
    "| 3 | 1002403 | THE VILLAGE OF HARLEM....NEW YORK ! | 78829239556 | unknown | Elise | Manhattan | Harlem | United States | US | True | Private room | 2005.0 | $620 | $124 | 3 | 0 | 5 | 1 |\n",
    "| 5 | 1003689 | Entire Apt: Spacious Studio/Loft by central park | 92037596077 | verified | Lyndon | Manhattan | East Harlem | United States | US | False | Entire home/apt | 2009.0 | $204 | $41 | 10 | 9 | 3 | 1 |\n",
    "| 6 | 1004098 | Large Cozy 1 BR Apartment In Midtown East | 45498551794 | verified | Michelle | Manhattan | Murray Hill | United States | US | True | Entire home/apt | 2013.0 | $577 | $115 | 3 | 74 | 3 | 1 |\n",
    "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
    "| 3630 | 2997901 | Brooklyn NY, Comfy,Spacious Repose! | 56267937797 | verified | Benjamin | Brooklyn | Bushwick | United States | US | False | Private room | 2007.0 | $767 | $153 | 3 | 40 | 2 | 1 |\n",
    "| 3631 | 2998453 | Upper West Side elegance. Riverside | 32040648122 | unconfirmed | Poppi | Manhattan | Upper West Side | United States | US | False | Entire home/apt | 2008.0 | $620 | $124 | 1 | 5 | 1 | 2 |\n",
    "| 3633 | 2999005 | BIG, BRIGHT, STYLISH + CONVENIENT | 40746270692 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3 | 90 | 2 | 1 |\n",
    "| 3634 | 2999005 | BIG, BRIGHT, STYLISH + CONVENIENT | 40746270692 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3 | 90 | 2 | 1 |\n",
    "| 3635 | 2999557 | Exclusive Upper East Side Studio | 24463750542 | verified | Ellen | Manhattan | Upper East Side | United States | US | True | Entire home/apt | 2022.0 | $655 | $131 | 1 | 0 | 5 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc1f8f4",
   "metadata": {},
   "source": [
    "3562 rows × 18 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a30d7d",
   "metadata": {},
   "source": [
    "# Removing Duplicates in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74700853",
   "metadata": {},
   "source": [
    "Duplicate data can occur in your DataFrame for a variety of reasons, and it’s often necessary to remove these duplicates in order to perform accurate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a39a918",
   "metadata": {},
   "source": [
    "# Identifying Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60bc240",
   "metadata": {},
   "source": [
    "Pandas provides the duplicated() function to identify duplicate rows. This function returns a Boolean Series that is True for each row that is a duplicate of a previous row and False otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a96f61",
   "metadata": {},
   "source": [
    "Now we will find out if there are duplicate data in the customer data that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7ddee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify duplicate rows\n",
    "airbnb_df.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f10fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "0       False\n",
    "1       False\n",
    "3       False\n",
    "5       False\n",
    "6       False\n",
    "        ...  \n",
    "3630     True\n",
    "3631    False\n",
    "3633    False\n",
    "3634     True\n",
    "3635    False\n",
    "Length: 3562, dtype: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870c5a7",
   "metadata": {},
   "source": [
    "By default, duplicated() considers all columns. If you look at the results, there is some duplicate data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc0497b",
   "metadata": {},
   "source": [
    "# Removing Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b89c43",
   "metadata": {},
   "source": [
    "Pandas provides the drop_duplicates() function to remove duplicate rows. This function returns a new DataFrame where duplicate rows have been removed. By default, drop_duplicates() considers all columns and keeps the first occurrence of each duplicate. If you want to consider only certain columns when dropping duplicates, or if you want to keep the last occurrence instead, you can pass arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a4dcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows in the original DataFrame\n",
    "airbnb_df.drop_duplicates(inplace=True)\n",
    "\n",
    "airbnb_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aad1f16",
   "metadata": {},
   "source": [
    "|  | id | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 3628 | 2997348 | East Village Studio | 29175111219 | unconfirmed | Sheila | Manhattan | East Village | United States | US | True | Entire home/apt | 2010.0 | $297 | $59 | 4 | 216 | 1 | 1 |\n",
    "| 3629 | 2997901 | Brooklyn NY, Comfy,Spacious Repose! | 56267937797 | verified | Benjamin | Brooklyn | Bushwick | United States | US | False | Private room | 2007.0 | $767 | $153 | 3 | 40 | 2 | 1 |\n",
    "| 3631 | 2998453 | Upper West Side elegance. Riverside | 32040648122 | unconfirmed | Poppi | Manhattan | Upper West Side | United States | US | False | Entire home/apt | 2008.0 | $620 | $124 | 1 | 5 | 1 | 2 |\n",
    "| 3633 | 2999005 | BIG, BRIGHT, STYLISH + CONVENIENT | 40746270692 | unconfirmed | Kerstin | Brooklyn | Bedford-Stuyvesant | United States | US | True | Private room | 2020.0 | $674 | $135 | 3 | 90 | 2 | 1 |\n",
    "| 3635 | 2999557 | Exclusive Upper East Side Studio | 24463750542 | verified | Ellen | Manhattan | Upper East Side | United States | US | True | Entire home/apt | 2022.0 | $655 | $131 | 1 | 0 | 5 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932208d3",
   "metadata": {},
   "source": [
    "Now, duplicate data has been removed. Remember, it’s important to understand your data and your specific use case before removing duplicates. Sometimes, what appears to be a duplicate might actually be valid data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c98288a",
   "metadata": {},
   "source": [
    "# Outlier Detection and Treatment in Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e4542f",
   "metadata": {},
   "source": [
    "Outliers are data points that are significantly different from other observations. They can be caused by variability in the data or experimental errors. Outliers can skew statistical measures and data distributions, leading to misleading results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c14cc88",
   "metadata": {},
   "source": [
    "# Detecting Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c26ff",
   "metadata": {},
   "source": [
    "There are several ways to detect outliers. A common method is to use the IQR (interquartile range) rule. The IQR is the range between the first quartile (25th percentile) and the third quartile (75th percentile) of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5be3039",
   "metadata": {},
   "source": [
    "Any data point that falls below the first quartile minus 1.5 times the IQR or above the third quartile plus 1.5 times the IQR is considered an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07eb190d",
   "metadata": {},
   "source": [
    "In this case we want to find out which hosts have the best value, but there are differences in data in the number_of_reviews column, therefore we need to identify which data are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415f25d6",
   "metadata": {},
   "source": [
    "Here’s how to detect outliers in the number_of_reviews column using IQR rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef938743",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = airbnb_df['number_of_reviews'].quantile(0.25)\n",
    "Q3 = airbnb_df['number_of_reviews'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define bounds\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "print(f\"lower bound: {lower_bound}\")\n",
    "print(f\"upper bound: {upper_bound}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5f74f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower bound: -113.5\n",
    "upper bound: 210.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf70f3ab",
   "metadata": {},
   "source": [
    "After we determine the lower and upper bound, we will identify which data are outliers in our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc710e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers\n",
    "outliers = airbnb_df[(airbnb_df['number_of_reviews'] < lower_bound) | (airbnb_df['number_of_reviews'] > upper_bound)]\n",
    "\n",
    "outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517c563",
   "metadata": {},
   "source": [
    "|  | id | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| 10 | 1005754 | Large Furnished Room Near B'way | 79384379533 | verified | Evelyn | Manhattan | Hell's Kitchen | United States | US | True | Private room | 2005.0 | $1,018 | $204 | 2 | 430 | 3 | 1 |\n",
    "| 21 | 1011277 | Chelsea Perfect | 73862528370 | verified | Alberta | Manhattan | Chelsea | United States | unknown | unknown | Private room | 2008.0 | $460 | unknown | 1 | 260 | 3 | 1 |\n",
    "| 34 | 1018457 | front room/double bed | 69410526955 | unconfirmed | Byron | Manhattan | Harlem | United States | unknown | unknown | Private room | 2004.0 | $770 | $154 | 3 | 242 | 3 | 3 |\n",
    "| 37 | 1020114 | back room/bunk beds | 25066620900 | verified | Alfred | Manhattan | Harlem | United States | unknown | unknown | Private room | 2021.0 | $545 | $109 | 3 | 273 | 3 | 3 |\n",
    "| 41 | 1022323 | Cute apt in artist's home | 88653822946 | verified | Joyce | Brooklyn | Bushwick | United States | US | True | Entire home/apt | 2005.0 | $1,097 | $219 | 2 | 231 | 3 | 2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f70aac6",
   "metadata": {},
   "source": [
    "In this example, outliers is a DataFrame that contains all rows in airbnb_df where number_of_reviews is an outlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8c287",
   "metadata": {},
   "source": [
    "Based on the previous results, data with id 1005754 is outlier data because it has number_of_reviews with a number above upper_bound (upper_bound = 210.5) of 430."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3871440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "airbnb_df.set_index('id', inplace=True)\n",
    "outlier_data = airbnb_df.loc[1005754]\n",
    "\n",
    "outlier_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name                              Large Furnished Room Near B'way\n",
    "host_id                                               79384379533\n",
    "host_identity_verified                                   verified\n",
    "host_name                                                  Evelyn\n",
    "neighbourhood_group                                     Manhattan\n",
    "neighbourhood                                      Hell's Kitchen\n",
    "country                                             United States\n",
    "country_code                                                   US\n",
    "instant_bookable                                             True\n",
    "room_type                                            Private room\n",
    "construction_year                                          2005.0\n",
    "price                                                     $1,018 \n",
    "service_fee                                                 $204 \n",
    "minimum_nights                                                  2\n",
    "number_of_reviews                                             430\n",
    "review_rate_number                                              3\n",
    "calculated_host_listings_count                                  1\n",
    "Name: 1005754, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9213325c",
   "metadata": {},
   "source": [
    "# Treating Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd44810d",
   "metadata": {},
   "source": [
    "Once you’ve detected outliers, you need to decide how to handle them. There are several strategies for this: - Removing outliers: If you’re confident that the outliers are due to errors, you might choose to remove them. - Capping outliers: Instead of removing outliers, you might choose to cap them at the lower and upper bounds. - Imputing outliers: Another strategy is to replace outliers with some imputed value, like the mean or median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3767bdc",
   "metadata": {},
   "source": [
    "# Removing Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd53f213",
   "metadata": {},
   "source": [
    "If you’re confident that the outliers in your data are due to errors, you might choose to remove them. This can be done using boolean indexing to create a new DataFrame that only includes rows where the value is not an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84d2ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "df_no_outliers = airbnb_df[(airbnb_df['number_of_reviews'] >= lower_bound) & (airbnb_df['number_of_reviews'] <= upper_bound)]\n",
    "\n",
    "df_no_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4424665",
   "metadata": {},
   "source": [
    "|  | name | host_id | host_identity_verified | host_name | neighbourhood_group | neighbourhood | country | country_code | instant_bookable | room_type | construction_year | price | service_fee | minimum_nights | number_of_reviews | review_rate_number | calculated_host_listings_count |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| id |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |\n",
    "| 1001254 | Clean & quiet apt home by the park | 80014485718 | unconfirmed | Madaline | Brooklyn | Kensington | United States | US | False | Private room | 2020.0 | $966 | $193 | 10 | 9 | 4 | 6 |\n",
    "| 1002102 | Skylit Midtown Castle | 52335172823 | verified | Jenna | Manhattan | Midtown | United States | US | False | Entire home/apt | 2007.0 | $142 | $28 | 30 | 45 | 4 | 2 |\n",
    "| 1002403 | THE VILLAGE OF HARLEM....NEW YORK ! | 78829239556 | unknown | Elise | Manhattan | Harlem | United States | US | True | Private room | 2005.0 | $620 | $124 | 3 | 0 | 5 | 1 |\n",
    "| 1003689 | Entire Apt: Spacious Studio/Loft by central park | 92037596077 | verified | Lyndon | Manhattan | East Harlem | United States | US | False | Entire home/apt | 2009.0 | $204 | $41 | 10 | 9 | 3 | 1 |\n",
    "| 1004098 | Large Cozy 1 BR Apartment In Midtown East | 45498551794 | verified | Michelle | Manhattan | Murray Hill | United States | US | True | Entire home/apt | 2013.0 | $577 | $115 | 3 | 74 | 3 | 1 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3107326",
   "metadata": {},
   "source": [
    "In this example, df_no_outliers is a new DataFrame where all outliers in the number_of_reviews column have been removed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4122cdc2",
   "metadata": {},
   "source": [
    "# Capping Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248eb74f",
   "metadata": {},
   "source": [
    "Instead of removing outliers, you might choose to cap them at the lower and upper bounds. This can be done using the clip() function, which caps values below a lower threshold at the lower threshold and values above an upper threshold at the upper threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708cded8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap outliers\n",
    "df_capped = airbnb_df.copy()\n",
    "df_capped['number_of_reviews'] = df_capped['number_of_reviews'].clip(lower_bound, upper_bound)\n",
    "\n",
    "outlier_data_capped = df_capped.loc[1005754]\n",
    "\n",
    "outlier_data_capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e3a935",
   "metadata": {},
   "outputs": [],
   "source": [
    "name                              Large Furnished Room Near B'way\n",
    "host_id                                               79384379533\n",
    "host_identity_verified                                   verified\n",
    "host_name                                                  Evelyn\n",
    "neighbourhood_group                                     Manhattan\n",
    "neighbourhood                                      Hell's Kitchen\n",
    "country                                             United States\n",
    "country_code                                                   US\n",
    "instant_bookable                                             True\n",
    "room_type                                            Private room\n",
    "construction_year                                          2005.0\n",
    "price                                                     $1,018 \n",
    "service_fee                                                 $204 \n",
    "minimum_nights                                                  2\n",
    "number_of_reviews                                           210.5\n",
    "review_rate_number                                              3\n",
    "calculated_host_listings_count                                  1\n",
    "Name: 1005754, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8602f820",
   "metadata": {},
   "source": [
    "In this example, df_capped is a new DataFrame with all outliers in the number_of_reviews column bounded at the bottom and top bounds. If you pay attention, the data with id 1005754 now has a value of number_of_reviews which has been adjusted to upper_bound of 210.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de736a59",
   "metadata": {},
   "source": [
    "# Imputing Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e544ff9",
   "metadata": {},
   "source": [
    "Another strategy is to replace outliers with some imputed value, like the mean, median, or mode. This can be done using boolean indexing to replace outlier values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70448cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute outliers with the median\n",
    "df_imputed = airbnb_df.copy()\n",
    "df_imputed.loc[(df_imputed['number_of_reviews'] < lower_bound) | (df_imputed['number_of_reviews'] > upper_bound), 'number_of_reviews'] = df_imputed['number_of_reviews'].median()\n",
    "\n",
    "outlier_data_imputed = df_imputed.loc[1005754]\n",
    "\n",
    "outlier_data_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f757a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "name                              Large Furnished Room Near B'way\n",
    "host_id                                               79384379533\n",
    "host_identity_verified                                   verified\n",
    "host_name                                                  Evelyn\n",
    "neighbourhood_group                                     Manhattan\n",
    "neighbourhood                                      Hell's Kitchen\n",
    "country                                             United States\n",
    "country_code                                                   US\n",
    "instant_bookable                                             True\n",
    "room_type                                            Private room\n",
    "construction_year                                          2005.0\n",
    "price                                                     $1,018 \n",
    "service_fee                                                 $204 \n",
    "minimum_nights                                                  2\n",
    "number_of_reviews                                              30\n",
    "review_rate_number                                              3\n",
    "calculated_host_listings_count                                  1\n",
    "Name: 1005754, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2efd2c5b",
   "metadata": {},
   "source": [
    "In this example, df_imputed is a new DataFrame where all outliers in the number_of_reviews column have been replaced with the median."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb3e514",
   "metadata": {},
   "source": [
    "# Exercise Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0f92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rggrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9cb3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title #### Student Identity\n",
    "student_id = \"your student id\" # @param {type:\"string\"}\n",
    "name = \"your name\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe781f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title #### 00. Filtering Data\n",
    "from rggrader import submit\n",
    "import pandas as pd\n",
    "\n",
    "students = {\n",
    "    'Name': ['Eric', 'Clay', 'Edward', 'Paul', 'Tara', 'Cris'],\n",
    "    'Math': [60, 76, 90, 55, 69, 88],\n",
    "    'Economy': [77, 83, 66, 71, 88, 91]\n",
    "}\n",
    "students_df = pd.DataFrame(students)\n",
    "\n",
    "# TODO: Filter students data where 'Math' and 'Economy' score are greater than 75\n",
    "# Put your code here:\n",
    "filtered_students = none\n",
    "\n",
    "\n",
    "# ---- End of your code ----\n",
    "\n",
    "# Submit Method\n",
    "assignment_id = \"00_pandas\"\n",
    "question_id = \"00_filtering-data\"\n",
    "submit(student_id, name, assignment_id, filtered_students.to_string(), question_id)\n",
    "\n",
    "# Expected Output:\n",
    "#    Name  Math  Economy\n",
    "# 1  Clay    76       83\n",
    "# 5  Cris    88       91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f619260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title #### 01. Replace Characters in string\n",
    "from rggrader import submit\n",
    "import pandas as pd\n",
    "\n",
    "cars = {\n",
    "    'Name': ['NSX', 'Supra', 'WRZ', 'Jesko', 'Veyron', 'P1'],\n",
    "    'Power': ['500HP', '512HP', '510HP', '700HP', '800HP', '600HP'],\n",
    "}\n",
    "cars_df = pd.DataFrame(cars)\n",
    "\n",
    "# TODO: Replace 'HP' character in 'Power' column\n",
    "# Put your code here:\n",
    "\n",
    "\n",
    "# ---- End of your code ----\n",
    "\n",
    "# Submit Method\n",
    "assignment_id = \"00_pandas\"\n",
    "question_id = \"01_replace-characters-in-string\"\n",
    "submit(student_id, name, assignment_id, cars_df.to_string(), question_id)\n",
    "\n",
    "# Expected Output:\n",
    "#      Name Power\n",
    "# 0     NSX   500\n",
    "# 1   Supra   512\n",
    "# 2     WRZ   510\n",
    "# 3   Jesko   700\n",
    "# 4  Veyron   800\n",
    "# 5      P1   600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336e1e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title #### 03. Fill missing value\n",
    "# from rggrader import submit\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "athletes = {\n",
    "    'Name': ['Eric', 'Clay', 'Edward', 'Paul', 'Tara', 'Cris'],\n",
    "    'Medals': [7, 4, np.NaN, 5, 8, np.NaN],\n",
    "}\n",
    "athletes_df = pd.DataFrame(athletes)\n",
    "\n",
    "# TODO: Fill the missing data in the 'Medals' column using the average of values\n",
    "# Put your code here: \n",
    "\n",
    "\n",
    "# ---- End of your code ----\n",
    "\n",
    "# Submit Method\n",
    "assignment_id = \"00_pandas\"\n",
    "question_id = \"02_fill-missing-value\"\n",
    "submit(student_id, name, assignment_id, athletes_df.to_string(), question_id)\n",
    "\n",
    "# Expected Output:\n",
    "#      Name  Medals\n",
    "# 0    Eric     7.0\n",
    "# 1    Clay     4.0\n",
    "# 2  Edward     6.0\n",
    "# 3    Paul     5.0\n",
    "# 4    Tara     8.0\n",
    "# 5    Cris     6.0"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
