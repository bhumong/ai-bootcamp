{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ac117dc",
   "metadata": {},
   "source": [
    "source: [link](https://ai-bootcamp.ruangguru.com/learn/06_computer-vision/01_stable-diffusion/01_basic/Stable_Diffusion_Basic.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b735630",
   "metadata": {},
   "source": [
    "# Stable Diffusion - Basic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55b149",
   "metadata": {},
   "source": [
    "[ ! Attention ] It’s crucial to verify the license of the models, particularly if there’s an intention to use the obtained results for commercial purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286d107",
   "metadata": {},
   "source": [
    "It’s essential to utilize these models responsibly and ethically. They should not be employed to create or disseminate illegal or harmful content. This includes, but is not limited to, content that is violent, hateful, sexually explicit, or infringes on someone’s privacy or rights."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d5acfa",
   "metadata": {},
   "source": [
    "As a user, the rights to the outputs generated using the model are retained. However, accountability for how these outputs are used also lies with the user. They should not be used in a manner that breaches the terms of the license or any applicable laws or regulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb246e2",
   "metadata": {},
   "source": [
    "The model can be used commercially or as a service, and the weights can be redistributed. However, if this is done, the same use restrictions as those in the original license must be included. A copy of the CreativeML OpenRAIL-M license must also be provided to all users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3168f61e",
   "metadata": {},
   "source": [
    "(Licence of v1.4 e v1.5 https://huggingface.co/spaces/CompVis/stable-diffusion-license)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f35352",
   "metadata": {},
   "source": [
    "With that out of the way, let’s try out various things we can do with Stable Diffusion. Let’s get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4cf7e9",
   "metadata": {},
   "source": [
    "> Note: - Some images when re-run will not be the same, even with the same seed. - Stable Diffusion is resource intensive in terms of need for GPU and large hard disk space, we may need to “disconnect and delete the runtime” and continue halfway through this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f36d4b5",
   "metadata": {},
   "source": [
    "Note: - Some images when re-run will not be the same, even with the same seed. - Stable Diffusion is resource intensive in terms of need for GPU and large hard disk space, we may need to “disconnect and delete the runtime” and continue halfway through this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733eb3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25535de5",
   "metadata": {},
   "source": [
    "# Installing the libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8983bff",
   "metadata": {},
   "source": [
    "- Install the necessary libraries for stable diffusion\n",
    "- xformersfor memory optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0069242",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install diffusers==0.11.1\n",
    "!pip install -q accelerate transformers ftfy bitsandbytes==0.35.0 gradio natsort safetensors xformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa40ad25",
   "metadata": {},
   "source": [
    "# Pipeline for image generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dfe106",
   "metadata": {},
   "source": [
    "- We can define with little effort a pipeline to use the Stable Diffusion model, through theStableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605b0105",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch #PyTorch\n",
    "from diffusers import StableDiffusionPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b593dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", torch_dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f99099b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = pipe.to('cuda') #We'll always use GPU, make sure your change your runtime to use GPU is you're on Collab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4a01b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.enable_attention_slicing()\n",
    "pipe.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d5e36b",
   "metadata": {},
   "source": [
    "Sometime during image generation, the image may come out all black, to avoid this we can disable safety checker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef54f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#avoid all black images, disabling it is easy, you can do this:\n",
    "pipe.safety_checker = lambda images, clip_input: (images, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07f77ba",
   "metadata": {},
   "source": [
    "# Creating the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca750f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'orange cat'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0dbb76",
   "metadata": {},
   "source": [
    "# Generating the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c344fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = pipe(prompt).images[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e921c2",
   "metadata": {},
   "source": [
    "# Display the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed764f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51067722",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "232078fb",
   "metadata": {},
   "source": [
    "# Saving the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cc4ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.save('result.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa9e0d3",
   "metadata": {},
   "source": [
    "# Let’s continue our experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb566705",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'photograph of orange cat, realistic, full hd'\n",
    "img = pipe(prompt).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4a94b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09e975",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'a photograph of orange cat'\n",
    "img = pipe(prompt).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28062ef",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7e5b9650",
   "metadata": {},
   "source": [
    "# Generating multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ac7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def grid_img(imgs, rows=1, cols=3, scale=1):\n",
    "  assert len(imgs) == rows * cols\n",
    "\n",
    "  w, h = imgs[0].size\n",
    "  w, h = int(w * scale), int(h * scale)\n",
    "\n",
    "  grid = Image.new('RGB', size = (cols * w, rows * h))\n",
    "  grid_w, grid_h = grid.size\n",
    "\n",
    "  for i, img in enumerate(imgs):\n",
    "    img = img.resize((w, h), Image.ANTIALIAS)\n",
    "    grid.paste(img, box=(i % cols * w, i // cols * h))\n",
    "  return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dde4e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 3\n",
    "prompt = 'photograph of orange cat'\n",
    "imgs = pipe(prompt, num_images_per_prompt=num_imgs).images\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc283e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e82cbc96",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27481632",
   "metadata": {},
   "source": [
    "There are some parameters we can set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301ea75e",
   "metadata": {},
   "source": [
    "# Seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb0709",
   "metadata": {},
   "source": [
    "We can set seed if we want to generate similar images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2000\n",
    "generator = torch.Generator('cuda').manual_seed(seed)\n",
    "img = pipe(prompt, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6d8873",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"photograph of orange cat\"\n",
    "seed = 2000\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "imgs = pipe(prompt, num_images_per_prompt=num_imgs, generator=generator).images\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c93292",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"van gogh painting of an orange cat\"\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "imgs = pipe(prompt, num_images_per_prompt=num_imgs, generator=generator).images\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268fa425",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df8644c1",
   "metadata": {},
   "source": [
    "# Inference steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80acac40",
   "metadata": {},
   "source": [
    "Inference steps refer to the number of denoising steps to reach the final image. The default number of inference steps of 50. If you want faster results you can use a smaller number. If you want potentially higher quality results, you can use larger numbers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df43b0c7",
   "metadata": {},
   "source": [
    "Let’s try out running the pipeline with less denoising steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f13d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"photograph of orange cat, realistic, full hd\"\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "img = pipe(prompt, num_inference_steps=3, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f076ef1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "for i in range(1, 6):\n",
    "  n_steps = i * 1\n",
    "  #print(n_steps)\n",
    "  generator = torch.Generator('cuda').manual_seed(seed)\n",
    "  img = pipe(prompt, num_inference_steps=n_steps, generator=generator).images[0]\n",
    "\n",
    "  plt.subplot(1, 5, i)\n",
    "  plt.title('num_inference_steps: {}'.format(n_steps))\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8532898c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "084df968",
   "metadata": {},
   "source": [
    "# Guidance Scale (CFG / Strength)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84ef87",
   "metadata": {},
   "source": [
    "CFG stands for Classifier-Free Guidance, so CFG scale can be referred to as Classifier-Free Guidance scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5691c9ff",
   "metadata": {},
   "source": [
    "So, before 2022, there was a method called classifier guidance. It’s a method that can balance between mode coverage and sample quality in diffusion models after training, similar to low-temperature sampling or truncation in other generative models. Essentially, classifier guidance is a mix between the score estimate from the diffusion model and the gradient from the image classifier. However, if we want to use it, we have to train an image classifier that’s different from the diffusion model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2f0679",
   "metadata": {},
   "source": [
    "Then, a question arises, can we have guidance without a classifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154051df",
   "metadata": {},
   "source": [
    "In 2022, Jonathan Ho and Tim Salimans from Google Brain demonstrated that we can use a pure generative model without a classifier. The title of their paper is “Classifier-Free Guidance”. They train both conditional and unconditional diffusion models together, then they combine the score estimates from both to achieve a trade-off between sample quality and diversity, similar to using classifier guidance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbd6183",
   "metadata": {},
   "source": [
    "It’s this CFG that Stable Diffusion uses to balance between the prompt and the Stable Diffusion model. If the CFG Scale is low, the image won’t follow the prompt. But if the CFG Scale is high, the result will be a random colorful image that doesn’t resemble the prompt at all."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae97dc80",
   "metadata": {},
   "source": [
    "The most suitable choice for CFG Scale is between 6.0 - 15.0. Lower values are good for photorealistic images, while higher values are suitable for a more artistic style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42acbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a man sit in front of the door\"\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "img = pipe(prompt, guidance_scale=7, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207e4f39",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7997603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,8))\n",
    "for i in range(1, 6):\n",
    "\n",
    "  n_guidance = i + 3\n",
    "  generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "  img = pipe(prompt, guidance_scale=n_guidance, generator=generator).images[0]\n",
    "\n",
    "  plt.subplot(1,5,i)\n",
    "  plt.title('guidance_scale: {}'.format(n_guidance))\n",
    "  plt.imshow(img)\n",
    "  plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868851d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "734273fa",
   "metadata": {},
   "source": [
    "# Image size (dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251dcad6",
   "metadata": {},
   "source": [
    "The generated images are 512 x 512 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41070f3",
   "metadata": {},
   "source": [
    "Recommendations in case you want other dimensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d9dcac",
   "metadata": {},
   "source": [
    "- make sure the height and width are multiples of 8\n",
    "- less than 512 will result in lower quality images\n",
    "- exceeding 512 in both directions (width and height) will repeat areas of the image (“global coherence” is lost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa3560b",
   "metadata": {},
   "source": [
    "> Landscape mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f04895f",
   "metadata": {},
   "source": [
    "Landscape mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778bffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "prompt = \"photograph of orange cat\"\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "h, w = 512, 512\n",
    "img = pipe(prompt, height=h, width=w, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0571fedd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8c7ae3fe",
   "metadata": {},
   "source": [
    "> Portrait mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1533f",
   "metadata": {},
   "source": [
    "Portrait mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b324984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "h, w = 768, 512\n",
    "img = pipe(prompt, height=h, width=w, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e62db",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ebb2b30",
   "metadata": {},
   "source": [
    "# Negative prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9da55d",
   "metadata": {},
   "source": [
    "We can use negative prompt to tell Stable Diffusion things we don’t want in our image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2182d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = 3\n",
    "\n",
    "prompt = 'photograph of old car'\n",
    "neg_prompt = 'black white'\n",
    "\n",
    "imgs = pipe(prompt, negative_prompt = neg_prompt, num_images_per_prompt=num_images).images\n",
    "\n",
    "grid = grid_img(imgs, rows = 1, cols = 3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50de785",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2710bac7",
   "metadata": {},
   "source": [
    "# Other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25bcc3f",
   "metadata": {},
   "source": [
    "# SD v1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027759bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd15 = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "sd15 = sd15.to('cuda')\n",
    "sd15.enable_attention_slicing()\n",
    "sd15.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_imgs = 3\n",
    "\n",
    "prompt = \"photograph of an old car\"\n",
    "neg_prompt = 'black white'\n",
    "\n",
    "imgs = sd15(prompt, negative_prompt=neg_prompt, num_images_per_prompt=num_imgs).images\n",
    "\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89a48e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b4383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"photo of a futuristic city on another planet, realistic, full hd\"\n",
    "neg_prompt = 'buildings'\n",
    "\n",
    "imgs = sd15(prompt, negative_prompt = neg_prompt, num_images_per_prompt=num_imgs).images\n",
    "\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee46e3b",
   "metadata": {},
   "source": [
    "# SD v2.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e7323",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2 = StableDiffusionPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-1\", torch_dtype=torch.float16)\n",
    "sd2 = sd2.to(\"cuda\")\n",
    "sd2.enable_attention_slicing()\n",
    "sd2.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7434b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"photograph of an old car\"\n",
    "neg_prompt = 'black white'\n",
    "\n",
    "\n",
    "imgs = sd2(prompt, negative_prompt=neg_prompt, num_images_per_prompt=num_imgs).images\n",
    "\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400375d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "939d2a43",
   "metadata": {},
   "source": [
    "# Fine-tuned models with specific styles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4fb238",
   "metadata": {},
   "source": [
    "> Mo-di-diffusion (Modern Disney style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d50cca4",
   "metadata": {},
   "source": [
    "Mo-di-diffusion (Modern Disney style)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19575f90",
   "metadata": {},
   "source": [
    "https://huggingface.co/nitrosocke/mo-di-diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63425eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "modi = StableDiffusionPipeline.from_pretrained(\"nitrosocke/mo-di-diffusion\", torch_dtype=torch.float16)\n",
    "modi = modi.to(\"cuda\")\n",
    "modi.enable_attention_slicing()\n",
    "modi.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481f458d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"a photograph of an astronaut riding a horse, modern disney style\"\n",
    "\n",
    "seed = 777\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "\n",
    "imgs = modi(prompt, generator=generator, num_images_per_prompt=num_imgs).images\n",
    "\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffcbbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"orange cat, modern disney style\"\n",
    "\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "imgs = modi(prompt, generator=generator, num_images_per_prompt=3).images\n",
    "\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.5)\n",
    "grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554462d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = [\"albert einstein, modern disney style\",\n",
    "          \"modern disney style old chevette driving in the desert, golden hour\",\n",
    "          \"modern disney style delorean\"]\n",
    "\n",
    "seed = 777\n",
    "print(\"Seed: \".format(str(seed)))\n",
    "generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
    "imgs = modi(prompt, generator=generator).images\n",
    "\n",
    "grid = grid_img(imgs, rows=1, cols=3, scale=0.75)\n",
    "grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fec2f1",
   "metadata": {},
   "source": [
    "# Other models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bbfc6a",
   "metadata": {},
   "source": [
    "- Classic Disney Style - https://huggingface.co/nitrosocke/classic-anim-diffusion\n",
    "- High resolution 3D animation - https://huggingface.co/nitrosocke/redshift-diffusion\n",
    "- Futuristic images - https://huggingface.co/nitrosocke/Future-Diffusion\n",
    "- Other animation styles:\n",
    "- https://huggingface.co/nitrosocke/Ghibli-Diffusion\n",
    "- https://huggingface.co/nitrosocke/spider-verse-diffusion\n",
    "- more models https://huggingface.co/models?other=stable-diffusion-diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d02e6c",
   "metadata": {},
   "source": [
    "Classic Disney Style - https://huggingface.co/nitrosocke/classic-anim-diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7716760",
   "metadata": {},
   "source": [
    "High resolution 3D animation - https://huggingface.co/nitrosocke/redshift-diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecee266",
   "metadata": {},
   "source": [
    "Futuristic images - https://huggingface.co/nitrosocke/Future-Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f48518b",
   "metadata": {},
   "source": [
    "Other animation styles:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b26f0f",
   "metadata": {},
   "source": [
    "https://huggingface.co/nitrosocke/Ghibli-Diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38742828",
   "metadata": {},
   "source": [
    "https://huggingface.co/nitrosocke/spider-verse-diffusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28283887",
   "metadata": {},
   "source": [
    "more models https://huggingface.co/models?other=stable-diffusion-diffusers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a56c5b7",
   "metadata": {},
   "source": [
    "# Changing the scheduler (sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f004fb0",
   "metadata": {},
   "source": [
    "We can also change the scheduler for our Stable Diffusion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cbf3d5",
   "metadata": {},
   "source": [
    "- Available schedulers: https://huggingface.co/docs/diffusers/using-diffusers/schedulers#schedulers-summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797eae4",
   "metadata": {},
   "source": [
    "Default is PNDMScheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8503eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd15 = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
    "sd15 = sd15.to(\"cuda\")\n",
    "sd15.enable_attention_slicing()\n",
    "sd15.enable_xformers_memory_efficient_attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abad781",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd15.scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1b88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 777\n",
    "prompt = \"a photo of a orange cat wearing sunglasses, on the beach, ocean in the background\"\n",
    "generator = torch.Generator('cuda').manual_seed(seed)\n",
    "img = sd15(prompt, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387e527e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd15.scheduler.compatibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e5ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd15.scheduler.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import DDIMScheduler\n",
    "sd15.scheduler = DDIMScheduler.from_config(sd15.scheduler.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44345cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = torch.Generator(device = 'cuda').manual_seed(seed)\n",
    "img = sd15(prompt, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1dda4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import LMSDiscreteScheduler\n",
    "sd15.scheduler = LMSDiscreteScheduler.from_config(sd15.scheduler.config)\n",
    "generator = torch.Generator(device = 'cuda').manual_seed(seed)\n",
    "img = sd15(prompt, num_inference_steps = 60, generator=generator).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import EulerAncestralDiscreteScheduler\n",
    "\n",
    "sd15.scheduler = EulerAncestralDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "img = sd15(prompt, generator=generator, num_inference_steps=50).images[0]\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers import EulerDiscreteScheduler\n",
    "\n",
    "sd15.scheduler = EulerDiscreteScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "generator = torch.Generator(device=\"cuda\").manual_seed(seed)\n",
    "img = sd15(prompt, generator=generator, num_inference_steps=50).images[0]\n",
    "img"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
