{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec20b891",
   "metadata": {},
   "source": [
    "# Hello World in Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce5409e",
   "metadata": {},
   "source": [
    "The classic “Hello World” when discussing image classification is using CNN on the MNIST dataset. The dataset contains 60,000-item where each MNIST image is a crude 28 x 28 pixel grayscale handwritten digit from “0” to “9.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354b93c1",
   "metadata": {},
   "source": [
    "# Regular NN on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84407e4a",
   "metadata": {},
   "source": [
    "Now, can we create an image classifier using a regular neural network (without CNN) ? Yes, we can, actually we already did it back when we are studying Machine Learning/Deep Learning. Here’s the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf26ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST solver\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load MNIST data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load MNIST data\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Use Data Loader\n",
    "train_loader = DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "# Train\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define model\n",
    "class MnistModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(784, 100)\n",
    "        self.hidden = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensors using reshape\n",
    "        xb = xb.reshape(-1, 784)\n",
    "        out = self.linear(xb)\n",
    "        out = self.hidden(out)\n",
    "        return out\n",
    "\n",
    "# Instantiate the model\n",
    "model = MnistModel()\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# Train\n",
    "total_epochs = 5\n",
    "for epoch in range(total_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        # Generate predictions\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # Perform gradient descent\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, total_epochs, loss.item()))\n",
    "\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    accum_acc = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        acc = accuracy(outputs, labels)\n",
    "        accum_acc += acc\n",
    "\n",
    "    print('Test loss: {:.4f}, Test accuracy: {:.4f}'.format(loss.item(), accum_acc/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc507cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch [1/5], Loss: 0.4527\n",
    "Epoch [2/5], Loss: 0.2594\n",
    "Epoch [3/5], Loss: 0.3485\n",
    "Epoch [4/5], Loss: 0.5416\n",
    "Epoch [5/5], Loss: 0.4624\n",
    "Test loss: 0.4252, Test accuracy: 0.9089"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca4513",
   "metadata": {},
   "source": [
    "Hey, it works, it also have 91% accuracy. There is no problem right ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82fc0c6",
   "metadata": {},
   "source": [
    "Well, on a simple image such as the MNIST dataset, which contains only black and white colors as well as simple shapes, that’s true. However, the images we encounter in the real world are far more complex and diverse in terms of colors, textures, and objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2889d6cc",
   "metadata": {},
   "source": [
    "To tackle these challenges effectively, specialized neural network architectures like Convolutional Neural Networks (CNNs) have emerged as the preferred choice, as they are designed to capture spatial hierarchies, local features, and patterns, making them well-suited for the diverse and intricate nature of real-world images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b070ec8",
   "metadata": {},
   "source": [
    "Note: - Spatial Hierarchies: The network can learn to recognize patterns, shapes, and structures in an image in a hierarchical manner. This involves identifying simple features (such as edges and corners) at lower levels and progressively combining them to recognize more complex and abstract objects or concepts at higher levels. - Local Features: The network can identify and focus on specific regions or elements within an image that are relevant for recognition or classification. These local features can be small patterns, textures, or details within an image that contribute to the overall understanding of what the image represents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360341c6",
   "metadata": {},
   "source": [
    "# CNN on MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a95162",
   "metadata": {},
   "source": [
    "Let’s try converting the code above to it’s CNN version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237a07ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a CNN model for MNIST\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64 * 5 * 5, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "# Load MNIST data\n",
    "mnist_train = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "mnist_test = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Use Data Loader\n",
    "train_loader = DataLoader(mnist_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(mnist_test, batch_size=100, shuffle=False)\n",
    "\n",
    "# Instantiate the CNN model\n",
    "cnn_model = CNNModel()\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# Training loop\n",
    "total_epochs = 5\n",
    "for epoch in range(total_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        outputs = cnn_model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, total_epochs, loss.item()))\n",
    "\n",
    "# Evaluation\n",
    "#cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    accum_acc = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = cnn_model(images)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        acc = accuracy(outputs, labels)\n",
    "        accum_acc += acc\n",
    "    \n",
    "    print('Test loss: {:.4f}, Test accuracy: {:.4f}'.format(loss.item(), accum_acc/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95e8e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "Epoch [1/5], Loss: 0.2483\n",
    "Epoch [2/5], Loss: 0.2432\n",
    "Epoch [3/5], Loss: 0.0879\n",
    "Epoch [4/5], Loss: 0.1307\n",
    "Epoch [5/5], Loss: 0.0887\n",
    "Test loss: 0.1283, Test accuracy: 0.9694"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ba62bf",
   "metadata": {},
   "source": [
    "Wow, 97% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b8016a",
   "metadata": {},
   "source": [
    "Our new code defines a CNN model with two convolutional layers followed by fully connected layers. It also normalizes the data to have a mean of 0.5 and a standard deviation of 0.5. Normalizing the data ensures that the pixel values have a consistent scale, usually between 0 and 1 or -1 and 1. This helps stabilize training, as large input values can lead to unstable gradients during backpropagation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964c66e",
   "metadata": {},
   "source": [
    "Still not convinced, well you can try modifying the code above to use the CIFAR10 which you can find on Huggingface. The CIFAR10 dataset presents a more complex challenge compared to MNIST due to its color images (32x32 pixels RGB) and diverse set of object categories (including animals, vehicles, and everyday objects)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07330386",
   "metadata": {},
   "source": [
    "We’ll skip the CIFAR10 notebook, but if you are interested in the result, you can visit this notebook: NN vs CNN CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842d09a9",
   "metadata": {},
   "source": [
    "Let’s continue to how CNN works."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
