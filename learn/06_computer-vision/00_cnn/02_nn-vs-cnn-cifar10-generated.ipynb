{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8707863",
   "metadata": {},
   "source": [
    "source: [link](https://ai-bootcamp.ruangguru.com/learn/06_computer-vision/00_cnn/02_nn-vs-cnn-cifar10.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8e65a4",
   "metadata": {},
   "source": [
    "# CIFAR10 comparison for regular Neural Network vs CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcc58a0",
   "metadata": {},
   "source": [
    "# CIFAR-10 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc69e18e",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77786687",
   "metadata": {},
   "source": [
    "The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0366296c",
   "metadata": {},
   "source": [
    "The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. “Automobile” includes sedans, SUVs, things of that sort. “Truck” includes only big trucks. Neither includes pickup trucks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83674792",
   "metadata": {},
   "source": [
    "Source: CIFAR 10 Dataset - cs.toronto.edu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad56e8",
   "metadata": {},
   "source": [
    "# Let’s explore the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb3dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a9c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Define data transformations (you can customize these)\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load the training dataset\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True, num_workers=2)\n",
    "\n",
    "# Define class labels\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# Function to display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # Unnormalize the image\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# Function to display a grid of images from a specified class with labels\n",
    "def show_images_from_class_with_labels(class_id, num_images=10):\n",
    "    # Find indices of images from the specified class\n",
    "    class_indices = [i for i, label in enumerate(trainset.targets) if label == class_id]\n",
    "    \n",
    "    # Randomly select num_images indices from the class\n",
    "    selected_indices = np.random.choice(class_indices, num_images, replace=False)\n",
    "    \n",
    "    # Create a grid for displaying images and labels\n",
    "    images_grid = []\n",
    "    labels_grid = []\n",
    "    \n",
    "    for idx in selected_indices:\n",
    "        image, label = trainset[idx]\n",
    "        # Convert image tensor to a NumPy array and reshape it from (C, H, W) to (H, W, C)\n",
    "        image = np.transpose(image.numpy(), (1, 2, 0))\n",
    "        \n",
    "        # Normalize the image data to be in the [0, 1] range\n",
    "        image = (image - image.min()) / (image.max() - image.min())\n",
    "        \n",
    "        images_grid.append(image)\n",
    "        \n",
    "    # Show the grid of images and one label for the class\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12, 1))  # Create a 1x2 grid of subplots\n",
    "    \n",
    "    axs[0].axis('off')  # Turn off axis for labels\n",
    "    axs[0].text(0.5, 0.5, f'Class: {classes[class_id]}', ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    axs[1].axis('off')  # Turn off axis for images\n",
    "    axs[1].imshow(np.concatenate(images_grid, axis=1))  # Concatenate images horizontally\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Display 10 random images from each class with labels\n",
    "for class_id, class_name in enumerate(classes):\n",
    "    show_images_from_class_with_labels(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457ef7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8a58aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "100%|██████████| 170498071/170498071 [43:03<00:00, 66006.41it/s]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132e7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Extracting ./data/cifar-10-python.tar.gz to ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cba9b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4a252e1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c06773e6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "876f45b0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74e9f3dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eae8ee35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "58720905",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dd9f84af",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8aeb5e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e302db1f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "887e3767",
   "metadata": {},
   "source": [
    "# Regular NN version:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2e288e",
   "metadata": {},
   "source": [
    "Let’s try again using the NN version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4996e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl #only for localhost\n",
    "ssl._create_default_https_context = ssl._create_unverified_context #only for localhost\n",
    "\n",
    "# MNIST solver\n",
    "\n",
    "import torch\n",
    "\n",
    "# Load MNIST data\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load MNIST data\n",
    "cifar10_train = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "cifar10_test = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Use Data Loader\n",
    "train_loader = DataLoader(cifar10_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=100, shuffle=False)\n",
    "\n",
    "# Train\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define model\n",
    "class FNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNNModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(3 * 32 * 32, 128)  # Adjust input size for CIFAR-10 (3 color channels, 32x32 pixels)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Flatten the input\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = FNNModel()\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define optimizer\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "# Train\n",
    "total_epochs = 10\n",
    "model.train()\n",
    "for epoch in range(5):\n",
    "    for images, labels in train_loader:\n",
    "        # Generate predictions\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        # Perform gradient descent\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, total_epochs, loss.item()))\n",
    "\n",
    "# Evaluate\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    accum_acc = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        acc = accuracy(outputs, labels)\n",
    "        accum_acc += acc\n",
    "\n",
    "    print('Test loss: {:.4f}, Test accuracy: {:.4f}'.format(loss.item(), accum_acc/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2910df",
   "metadata": {},
   "outputs": [],
   "source": [
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch [1/10], Loss: 1.8312\n",
    "Epoch [2/10], Loss: 1.7067\n",
    "Epoch [3/10], Loss: 1.6943\n",
    "Epoch [4/10], Loss: 1.5868\n",
    "Epoch [5/10], Loss: 1.5829\n",
    "Test loss: 1.5123, Test accuracy: 0.4600"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2f1d97",
   "metadata": {},
   "source": [
    "Only 46% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51dc5553",
   "metadata": {},
   "source": [
    "# CNN Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852555e5",
   "metadata": {},
   "source": [
    "Let’s also try the CNN version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60600e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define a CNN model for CIFAR-10\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)  # Adjust input channels for CIFAR-10 (3 color channels)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64 * 6 * 6, 128)  # Adjust input size for CIFAR-10 (32x32 images)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10 classes for CIFAR-10\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define data transformations\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Load CIFAR-10 data\n",
    "cifar10_train = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
    "cifar10_test = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# Use Data Loader\n",
    "train_loader = DataLoader(cifar10_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(cifar10_test, batch_size=100, shuffle=False)\n",
    "\n",
    "# Instantiate the CNN model\n",
    "cnn_model = CNNModel()\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.01\n",
    "optimizer = optim.SGD(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define accuracy function\n",
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))\n",
    "\n",
    "total_epochs = 10\n",
    "# Training loop\n",
    "cnn_model.train()\n",
    "for epoch in range(total_epochs):\n",
    "    for images, labels in train_loader:\n",
    "        outputs = cnn_model(images)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, total_epochs, loss.item()))\n",
    "\n",
    "# Evaluation\n",
    "cnn_model.eval()\n",
    "with torch.no_grad():\n",
    "    accum_acc = 0\n",
    "    for images, labels in test_loader:\n",
    "        outputs = cnn_model(images)\n",
    "\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        acc = accuracy(outputs, labels)\n",
    "        accum_acc += acc\n",
    "    \n",
    "    print('Test loss: {:.4f}, Test accuracy: {:.4f}'.format(loss.item(), accum_acc/len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2975c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Files already downloaded and verified\n",
    "Files already downloaded and verified\n",
    "Epoch [1/10], Loss: 2.1188\n",
    "Epoch [2/10], Loss: 1.9551\n",
    "Epoch [3/10], Loss: 1.6204\n",
    "Epoch [4/10], Loss: 1.5244\n",
    "Epoch [5/10], Loss: 1.4974\n",
    "Epoch [6/10], Loss: 1.3608\n",
    "Epoch [7/10], Loss: 1.4381\n",
    "Epoch [8/10], Loss: 1.3200\n",
    "Epoch [9/10], Loss: 1.2991\n",
    "Epoch [10/10], Loss: 1.1985\n",
    "Test loss: 1.2555, Test accuracy: 0.5520"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29441bda",
   "metadata": {},
   "source": [
    "Wow, 55% accuracy!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78d997",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3a6a7",
   "metadata": {},
   "source": [
    "We can see the gap widens now, 45% vs 55%, compared to 91% vs 97% on the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c6c52a",
   "metadata": {},
   "source": [
    "You can increase the epochs to find out when one of model reaches 90%, which one do you think ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d4dcb",
   "metadata": {},
   "source": [
    "I hope I make my point across that CNN is far superior to regular NN when we are working with images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11109f11",
   "metadata": {},
   "source": [
    "# Exercise CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d5186",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rggrader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3abc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title #### Student Identity\n",
    "student_id = \"student_id\" # @param {type:\"string\"}\n",
    "name = \"your_name\" # @param {type:\"string\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2daac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title #### 00. CIFAR10 Dataset Accuracy\n",
    "\n",
    "from rggrader import submit\n",
    "\n",
    "# TODO: Improve the accuracy of the CNN model using the CIFAR10 dataset above. Write your code here.\n",
    "\n",
    "# You may add any code here to derive your variables\n",
    "# Please change this\n",
    "accuracy = 5\n",
    "\n",
    "print(f\"The accuracy is {accuracy}\")\n",
    "\n",
    "\n",
    "# Submit Method\n",
    "assignment_id = \"03_cnn\"\n",
    "question_id = \"00_cifar10_accuracy\"\n",
    "submit(student_id, name, assignment_id, str(accuracy), question_id, \"\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
