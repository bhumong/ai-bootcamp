{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a2073cc",
   "metadata": {},
   "source": [
    "source: [link](https://ai-bootcamp.ruangguru.com/learn/06_computer-vision/00_cnn/03_convolution-layer.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c8eccc",
   "metadata": {},
   "source": [
    "# Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4815f2",
   "metadata": {},
   "source": [
    "Let’s see how CNN actually does it’s magic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628b3a96",
   "metadata": {},
   "source": [
    "CNN is short for Convolutional Neural Network, and convolution process as well as mathematical formula is the primary factor. Now, before we go deeper into the math, let’s check out how the convolution process works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2beec7ae",
   "metadata": {},
   "source": [
    "# Convolution Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcb3034",
   "metadata": {},
   "source": [
    "The convolution process refers to the action of mapping a filter called kernel across the image and performing a convolution mathematical operations to produce a feature map. It’s easier to show an animation of this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3b79d7",
   "metadata": {},
   "source": [
    " (Source: Miro)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449fc09c",
   "metadata": {},
   "source": [
    "![Image](https://storage.googleapis.com/rg-ai-bootcamp/cnn/illustration-convolution-operation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d1431b",
   "metadata": {},
   "source": [
    "In the animation above, we can see an image of 5x5 being convoluted with a 3x3 kernel resulting in a 3x3 feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23dbeae",
   "metadata": {},
   "source": [
    "# Convolution Operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0ea07c",
   "metadata": {},
   "source": [
    "The convolution operation of two arrays $a$ and $b$ is denoted by $a * b$ and defined as:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2b8702",
   "metadata": {},
   "source": [
    "\n",
    "\\[\n",
    "(a * b)_{n} = \\sum_{i=1} a_{i} b_{n-i}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94e7dce",
   "metadata": {},
   "source": [
    "Let’s see how this works in practice. Let’s say we have an $A$ is $[1, 2, 3, 4, 5]$ and $B$ is $[10, 9, 8]$. The convolution operation of $A$ and $B$ is:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dd1dc9",
   "metadata": {},
   "source": [
    "\n",
    "\\[\n",
    "\\begin{align}\n",
    "(a * b)_{2} &= \\sum_{i=1} a_{i} b_{2-i} \\\\\n",
    "&= a_{1} b_{1}\n",
    "\\end{align}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efcc00",
   "metadata": {},
   "source": [
    "\n",
    "\\[\n",
    "\\begin{align}\n",
    "(a * b)_{3} &= \\sum_{i=1} a_{i} b_{3-i} \\\\\n",
    "&= a_{1} b_{2} + a_{2} b_{1}\n",
    "\\end{align}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e11851",
   "metadata": {},
   "source": [
    "\n",
    "\\[\n",
    "\\begin{align}\n",
    "(a * b)_{4} &= \\sum_{i=1} a_{i} b_{4-i} \\\\\n",
    "&= a_{1} b_{3} + a_{2} b_{2} + a_{3} b_{1}\n",
    "\\end{align}\n",
    "\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57aff98",
   "metadata": {},
   "source": [
    "Confusing? Let’s watch the following video, it’s actually pretty simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0648afc6",
   "metadata": {},
   "source": [
    "# Convolution Operation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1def5b8e",
   "metadata": {},
   "source": [
    "In Python, we can use numpy.convolve to perform the convolution operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f07f26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "\n",
    "print(np.convolve(a, b, 'full'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb15abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ 4 13 28 27 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9016c6",
   "metadata": {},
   "source": [
    "same parameter will make sure the output has the same length as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd9991a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "\n",
    "print(np.convolve(a, b, 'same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2b280",
   "metadata": {},
   "outputs": [],
   "source": [
    "[13 28 27]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac06495",
   "metadata": {},
   "source": [
    "valid parameter will make sure the calculation is only performed where the input and the filter fully overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d556997",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6]\n",
    "\n",
    "print(np.convolve(a, b, 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc87dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[28]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26dbe8ff",
   "metadata": {},
   "source": [
    "In the above example, the output is only calculated for $1 * 6 + 2 * 5 + 3 * 4 = 28$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd58f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = [1, 2, 3]\n",
    "b = [4, 5, 6, 7]\n",
    "\n",
    "print(np.convolve(a, b, 'valid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f059ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "[28 34]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6488869c",
   "metadata": {},
   "source": [
    "How about 2D?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb53e43",
   "metadata": {},
   "source": [
    "It’s possible to use numpy to perform 2D convolution operation, but it’s not as simple as 1D. We’ll use scipy.signal.convolve2d instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e45f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "# Given arrays\n",
    "a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "b = np.array([[1, 0], [1, 0]])\n",
    "\n",
    "# 'valid' means that we only compute the convolution where the input arrays fully overlap\n",
    "c = convolve2d(a, b, mode='valid')\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c197f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[ 7  9]\n",
    " [13 15]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e154ef",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98582e",
   "metadata": {},
   "source": [
    "But that still doesn’t answer how does this process help detect edges ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6200949f",
   "metadata": {},
   "source": [
    "> Note: To better illustrate, we prepare a spreadsheet for a quick simulation of Convolution:GSheet Link\n",
    "> So you can try it for yourself, it’s much easier using Google Sheet. Remember to make a copy for your own use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721a4ec6",
   "metadata": {},
   "source": [
    "Note: To better illustrate, we prepare a spreadsheet for a quick simulation of Convolution: GSheet Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def4a49a",
   "metadata": {},
   "source": [
    "So you can try it for yourself, it’s much easier using Google Sheet. Remember to make a copy for your own use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304aa1b4",
   "metadata": {},
   "source": [
    "Now, let’s put this knowledge into action:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00c26a",
   "metadata": {},
   "source": [
    "Let’s say we have a 16x16 grid containing a letter H. And we have a 3x3 kernel with the identity, meaning the only activated is the center number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b83ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "0 0 0\n",
    "0 1 0\n",
    "0 0 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b3ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib numpy scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5813f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def simulate_convolution(input_grid, kernel):\n",
    "    # Get the size of the input grid\n",
    "    grid_size = input_grid.shape[0]\n",
    "\n",
    "    # Perform convolution\n",
    "    feature_map = convolve2d(input_grid, kernel, 'same')\n",
    "\n",
    "    # Create a figure and subplots\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    # Plot the input grid on the left\n",
    "    axs[0].imshow(input_grid, cmap='gray')\n",
    "    axs[0].set_title('Input Grid')\n",
    "\n",
    "    # Plot the kernel in the middle\n",
    "    axs[1].imshow(kernel, cmap='gray')\n",
    "    axs[1].set_title('Kernel')\n",
    " \n",
    "    # Plot the feature map on the right\n",
    "    axs[2].imshow(feature_map, cmap='gray')\n",
    "    axs[2].set_title('Feature Map')\n",
    "\n",
    "    # Remove axis labels and ticks\n",
    "    for ax in axs:\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    # Show the grids\n",
    "    plt.show()\n",
    "\n",
    "    print(\"input_grid\", input_grid, sep='\\n')\n",
    "    print(\"kernel\", kernel, sep='\\n')\n",
    "    print(\"feature_map\", feature_map, sep='\\n')\n",
    "\n",
    "# Create a 16x16 input grid with the letter \"H\"\n",
    "grid_size = 16\n",
    "input_grid = np.zeros((grid_size, grid_size))\n",
    "\n",
    "# Draw the letter \"H\" on the input grid\n",
    "# Horizontal line\n",
    "input_grid[7, 3:12] = 1\n",
    "# Vertical lines\n",
    "input_grid[4:12, 3] = 1\n",
    "input_grid[4:12, 12] = 1\n",
    "\n",
    "# Create a 3x3 identity kernel\n",
    "conv_kernel = np.array([[0, 0, 0],\n",
    "                       [0, 1, 0],\n",
    "                       [0, 0, 0]])\n",
    "\n",
    "# Call the function to simulate convolution\n",
    "simulate_convolution(input_grid, conv_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c1e38f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1344cd",
   "metadata": {},
   "source": [
    "The result on the right is the same letter, what happens if we change the kernel to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54db973",
   "metadata": {},
   "outputs": [],
   "source": [
    "0.00    0.20    0.00\n",
    "0.20    0.20    0.20\n",
    "0.00    0.20    0.00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59933d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 blur kernel\n",
    "conv_kernel = np.array([[0, 0.2, 0],\n",
    "                        [0.2, 0.2, 0.2],\n",
    "                        [0, 0.2, 0]])\n",
    "\n",
    "# Call the function to simulate convolution\n",
    "simulate_convolution(input_grid, conv_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbb3d82",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b13e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grid\n",
    "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "kernel\n",
    "[[0.  0.2 0. ]\n",
    " [0.2 0.2 0.2]\n",
    " [0.  0.2 0. ]]\n",
    "feature_map\n",
    "[[0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    " [0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0. ]\n",
    " [0.  0.  0.2 0.4 0.2 0.  0.  0.  0.  0.  0.  0.2 0.4 0.2 0.  0. ]\n",
    " [0.  0.  0.2 0.6 0.2 0.  0.  0.  0.  0.  0.  0.2 0.6 0.2 0.  0. ]\n",
    " [0.  0.  0.2 0.6 0.4 0.2 0.2 0.2 0.2 0.2 0.2 0.4 0.6 0.2 0.  0. ]\n",
    " [0.  0.  0.2 0.8 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.6 0.8 0.2 0.  0. ]\n",
    " [0.  0.  0.2 0.6 0.4 0.2 0.2 0.2 0.2 0.2 0.2 0.4 0.6 0.2 0.  0. ]\n",
    " [0.  0.  0.2 0.6 0.2 0.  0.  0.  0.  0.  0.  0.2 0.6 0.2 0.  0. ]\n",
    " [0.  0.  0.2 0.6 0.2 0.  0.  0.  0.  0.  0.  0.2 0.6 0.2 0.  0. ]\n",
    " [0.  0.  0.2 0.4 0.2 0.  0.  0.  0.  0.  0.  0.2 0.4 0.2 0.  0. ]\n",
    " [0.  0.  0.  0.2 0.  0.  0.  0.  0.  0.  0.  0.  0.2 0.  0.  0. ]\n",
    " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]\n",
    " [0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0. ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e684855",
   "metadata": {},
   "source": [
    "The image is blurred right ? Now, as we change the kernel, the feature map will change accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553deb9",
   "metadata": {},
   "source": [
    "Can we use the kernel to detect horizontal line and vertical line ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253ee02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 vertical line detection kernel\n",
    "conv_kernel = np.array([[0, 1, 0],\n",
    "                        [0, 1, 0],\n",
    "                        [0, 1, 0]])\n",
    "\n",
    "# Call the function to simulate convolution\n",
    "simulate_convolution(input_grid, conv_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e84b3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72318e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grid\n",
    "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "kernel\n",
    "[[0 1 0]\n",
    " [0 1 0]\n",
    " [0 1 0]]\n",
    "feature_map\n",
    "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
    " [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.]\n",
    " [0. 0. 0. 3. 1. 1. 1. 1. 1. 1. 1. 1. 3. 0. 0. 0.]\n",
    " [0. 0. 0. 3. 1. 1. 1. 1. 1. 1. 1. 1. 3. 0. 0. 0.]\n",
    " [0. 0. 0. 3. 1. 1. 1. 1. 1. 1. 1. 1. 3. 0. 0. 0.]\n",
    " [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.]\n",
    " [0. 0. 0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 3. 0. 0. 0.]\n",
    " [0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 2. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b8cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 3x3 vertical line detection kernel\n",
    "conv_kernel = np.array([[0, 0, 0],\n",
    "                        [1, 1, 1],\n",
    "                        [0, 0, 0]])\n",
    "\n",
    "# Call the function to simulate convolution\n",
    "simulate_convolution(input_grid, conv_kernel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220e0cb1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeff449",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_grid\n",
    "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
    "kernel\n",
    "[[0 0 0]\n",
    " [1 1 1]\n",
    " [0 0 0]]\n",
    "feature_map\n",
    "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
    " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
    " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
    " [0. 0. 1. 2. 3. 3. 3. 3. 3. 3. 3. 3. 2. 1. 0. 0.]\n",
    " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
    " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
    " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
    " [0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f1f005",
   "metadata": {},
   "source": [
    "Yes we can!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321788a3",
   "metadata": {},
   "source": [
    "# Convolution Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9e40e",
   "metadata": {},
   "source": [
    "Again, we prepare a spreadsheet for a quick simulation of Convolution: GSheet Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46db5915",
   "metadata": {},
   "source": [
    "So you can try it for yourself, it’s much easier using Google Sheet. Remember to make a copy for your own use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8a6d8d",
   "metadata": {},
   "source": [
    "# Convolution Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c2dbc6",
   "metadata": {},
   "source": [
    "The input data to a convolutional layer is usually in 3-dimensions: height, width and depth. Height and weight clearly refers to the dimension of the image. But what about depth ? Depth here simply refers to the image channels, in the case of RGB it has a depth of 3, for grayscale image it has a depth of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e127d9f4",
   "metadata": {},
   "source": [
    "# Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52514f02",
   "metadata": {},
   "source": [
    "The convolution layer then takes the input and apply the kernel to an area of the image and a dot product is calculated between the input pixels and the kernel. The kernel size is usually 3x3 but it can be adjusted. A larger kernel naturally covers a larger area and better detect large shapes or objects but less adapt to detecting the finer details such as edges, corners or textures which are better performed with a small kernel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faafe95d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d510647e",
   "metadata": {},
   "source": [
    "![Image](https://storage.googleapis.com/rg-ai-bootcamp/cnn/convolution-animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8422a373",
   "metadata": {},
   "source": [
    "Source: Hochschule Der Medien"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb8f462",
   "metadata": {},
   "source": [
    "Then how can we create a kernel matrix? Is it by hand or is there a way to create it automatically?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38849c32",
   "metadata": {},
   "source": [
    "Well, it turns out we can define the kernel size, but the kernel matrix itself is learned by the CNN Neural Network. Here’s how it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a862a8c",
   "metadata": {},
   "source": [
    "- Initially the values within the kernel matrix are randomly initialized. These random values do not represent any specific pattern.\n",
    "- During the training process of the CNN, the network learns the optimal values for the kernel matrix by adjusting the values within the kernel to minimize the error.\n",
    "- Once training is complete, the learned kernel matrix is then used for feature extraction during the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a278e735",
   "metadata": {},
   "source": [
    "# Strides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536357da",
   "metadata": {},
   "source": [
    "We know that the kernel moves across the image, but how it moves and steps from one position to another is determined by a parameter known as “strides.”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0527ea61",
   "metadata": {},
   "source": [
    "Strides dictate the amount by which the kernel shifts its position as it scans the input data. Specifically, strides control both the horizontal and vertical movement of the kernel during the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f23d8c2",
   "metadata": {},
   "source": [
    "Larger stepsizes yield a correspondingly smaller output. In the picture below filtering with stepsize of $ s = 2 $ is shown below filtering the same input with a stepsize of $ s = 1 $."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873322a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c63e3391",
   "metadata": {},
   "source": [
    "![Image](https://storage.googleapis.com/rg-ai-bootcamp/cnn/conv-step-size-small.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171251da",
   "metadata": {},
   "source": [
    "# Padding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39177ae",
   "metadata": {},
   "source": [
    "Padding is usually applied on the input image by adding additional rows and columns around its border before convolution starts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa37f428",
   "metadata": {},
   "source": [
    "The objective is to ensure that the convolution operation considers the pixels at the borders of the input image, preventing information loss and border effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b474c794",
   "metadata": {},
   "source": [
    "The most commonly used padding is zero-padding because of its performance, simplicity, and computational efficiency. The technique involves adding zeros symmetrically around the edges of an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be407881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using numpy to create 5x5 matrix, with random values\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# init random seed\n",
    "np.random.seed(0)\n",
    "\n",
    "a = np.random.rand(5, 5)\n",
    "# print a nicely\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "print(\"Original matrix\")\n",
    "print(a)\n",
    "print()\n",
    "\n",
    "\n",
    "# add 0 to the left and right of the matrix\n",
    "b = np.pad(a, pad_width=1, mode='constant', constant_values=0)\n",
    "print(\"After padding, p = 1\")\n",
    "print(b)\n",
    "\n",
    "# we can also pad more than one row or column\n",
    "c = np.pad(a, pad_width=2, mode='constant', constant_values=0)\n",
    "print(\"After padding, p = 2\")\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad31593",
   "metadata": {},
   "outputs": [],
   "source": [
    "Original matrix\n",
    "[[0.549 0.715 0.603 0.545 0.424]\n",
    " [0.646 0.438 0.892 0.964 0.383]\n",
    " [0.792 0.529 0.568 0.926 0.071]\n",
    " [0.087 0.02  0.833 0.778 0.87 ]\n",
    " [0.979 0.799 0.461 0.781 0.118]]\n",
    "\n",
    "After padding\n",
    "[[0.    0.    0.    0.    0.    0.    0.   ]\n",
    " [0.    0.549 0.715 0.603 0.545 0.424 0.   ]\n",
    " [0.    0.646 0.438 0.892 0.964 0.383 0.   ]\n",
    " [0.    0.792 0.529 0.568 0.926 0.071 0.   ]\n",
    " [0.    0.087 0.02  0.833 0.778 0.87  0.   ]\n",
    " [0.    0.979 0.799 0.461 0.781 0.118 0.   ]\n",
    " [0.    0.    0.    0.    0.    0.    0.   ]]\n",
    "After padding\n",
    "[[0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
    " [0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
    " [0.    0.    0.549 0.715 0.603 0.545 0.424 0.    0.   ]\n",
    " [0.    0.    0.646 0.438 0.892 0.964 0.383 0.    0.   ]\n",
    " [0.    0.    0.792 0.529 0.568 0.926 0.071 0.    0.   ]\n",
    " [0.    0.    0.087 0.02  0.833 0.778 0.87  0.    0.   ]\n",
    " [0.    0.    0.979 0.799 0.461 0.781 0.118 0.    0.   ]\n",
    " [0.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
    " [0.    0.    0.    0.    0.    0.    0.    0.    0.   ]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e40d630",
   "metadata": {},
   "source": [
    "# ACTIVATION FUNCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4646698",
   "metadata": {},
   "source": [
    "We perform an Activation function after every convolutional layer in the network architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbdbaf7",
   "metadata": {},
   "source": [
    "The ReLU activation function is specifically used as a non-linear activation function, as opposed to other non-linear functions such as Sigmoid because it has been empirically observed that CNNs using ReLU are faster to train than their counterparts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbc730c",
   "metadata": {},
   "source": [
    "# How to create kernel matrix?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ec46b",
   "metadata": {},
   "source": [
    "Then how can we create a kernel matrix? Is it by hand or is there a way to create it automatically?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ffa8e9",
   "metadata": {},
   "source": [
    "Well, it turns out we can define the kernel size, but the kernel matrix itself is learned by the CNN Neural Network. Here’s how it works:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14c8fee",
   "metadata": {},
   "source": [
    "- Initially the values within the kernel matrix are randomly initialized. These random values do not represent any specific pattern.\n",
    "- During the training process of the CNN, the network learns the optimal values for the kernel matrix by adjusting the values within the kernel to minimize the error.\n",
    "- Once training is complete, the learned kernel matrix is then used for feature extraction during the convolution operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cd8521",
   "metadata": {},
   "source": [
    "# Size of the output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708bd835",
   "metadata": {},
   "source": [
    "The size of the output feature map is controlled by stride and padding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cc7cce",
   "metadata": {},
   "source": [
    "\n",
    "\\[\n",
    "W_{out} = \\frac{W_{in} - F + 2P}{S} + 1\n",
    "\\]\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
